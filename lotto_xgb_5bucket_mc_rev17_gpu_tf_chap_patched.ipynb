{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563910e0",
   "metadata": {},
   "source": [
    "# Lotto XGBoost with 5-Number Buckets (Named Ranges)\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads `Lotto_DATE.xlsx` (NZ Lotto draw history).\n",
    "2. Builds **5-number bucket features** with meaningful names, e.g. `bucket_1_5_count`, `bucket_6_10_count`, etc.\n",
    "3. Adds simple extra features (Odd/Even, date parts, etc.).\n",
    "4. Trains an **XGBoost multi-output regressor** (one target per winning number).\n",
    "5. Performs 5-fold cross-validation.\n",
    "6. Demonstrates generating candidate draws and predicting with the best model.\n",
    "7. Saves the expanded dataset (with new features) as `Lotto_DATE_Imputed.xlsx`.\n",
    "\n",
    "Place this notebook in the same folder as `Lotto5.xlsx` and run all cells top to bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d7495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Configuring NVIDIA GPU for TensorFlow/XGBoost\n",
      "======================================================================\n",
      "✓ CUDA path:         C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\n",
      "✓ cuDNN path:        C:\\Program Files\\NVIDIA\\CUDNN\\v9.16\n",
      "✓ cuDNN variant:     13.0\n",
      "✓ cuDNN bin:         C:\\Program Files\\NVIDIA\\CUDNN\\v9.16\\bin\\13.0\n",
      "✓ cuDNN lib:         C:\\Program Files\\NVIDIA\\CUDNN\\v9.16\\lib\\13.0\n",
      "✓ PATH updated with CUDA and cuDNN binaries\n",
      "✓ TF_FORCE_GPU_ALLOW_GROWTH = True\n",
      "✓ Ready to import TensorFlow with GPU support\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# ===================================================================\n",
    "# GPU/CUDA/cuDNN INITIALIZATION - MUST RUN BEFORE ANY TF IMPORT\n",
    "# ===================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Configuring NVIDIA GPU for TensorFlow/XGBoost\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set paths for CUDA 12.1 and cuDNN 9.16\n",
    "CUDA_PATH = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\"\n",
    "CUDNN_PATH = r\"C:\\Program Files\\NVIDIA\\CUDNN\\v9.16\"\n",
    "\n",
    "# Configure environment variables BEFORE importing TensorFlow\n",
    "os.environ['CUDA_PATH'] = CUDA_PATH\n",
    "os.environ['CUDA_HOME'] = CUDA_PATH\n",
    "os.environ['CUDNN_PATH'] = CUDNN_PATH\n",
    "\n",
    "# Try cuDNN 13.0 for better compatibility with CUDA 12.1\n",
    "# If 13.0 doesn't work, will fall back to 12.9\n",
    "cuda_bin = os.path.join(CUDA_PATH, 'bin')\n",
    "cudnn_bin_13_0 = os.path.join(CUDNN_PATH, 'bin', '13.0')\n",
    "cudnn_lib_13_0 = os.path.join(CUDNN_PATH, 'lib', '13.0')\n",
    "\n",
    "# Fall back to 12.9 if 13.0 doesn't exist\n",
    "if not os.path.exists(cudnn_bin_13_0):\n",
    "    cudnn_bin_13_0 = os.path.join(CUDNN_PATH, 'bin', '12.9')\n",
    "    cudnn_lib_13_0 = os.path.join(CUDNN_PATH, 'lib', '12.9')\n",
    "\n",
    "os.environ['PATH'] = os.pathsep.join([\n",
    "    cuda_bin,\n",
    "    cudnn_bin_13_0,\n",
    "    cudnn_lib_13_0,\n",
    "    os.environ.get('PATH', '')\n",
    "])\n",
    "\n",
    "# Set TensorFlow CUDA configuration\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Try to suppress CUDA initialization warnings\n",
    "os.environ['TF_CPP_VMODULE'] = 'gpu_device=2'\n",
    "\n",
    "cudnn_variant = '13.0' if '13.0' in cudnn_bin_13_0 else '12.9'\n",
    "print(f\"✓ CUDA path:         {CUDA_PATH}\")\n",
    "print(f\"✓ cuDNN path:        {CUDNN_PATH}\")\n",
    "print(f\"✓ cuDNN variant:     {cudnn_variant}\")\n",
    "print(f\"✓ cuDNN bin:         {cudnn_bin_13_0}\")\n",
    "print(f\"✓ cuDNN lib:         {cudnn_lib_13_0}\")\n",
    "print(f\"✓ PATH updated with CUDA and cuDNN binaries\")\n",
    "print(f\"✓ TF_FORCE_GPU_ALLOW_GROWTH = True\")\n",
    "print(f\"✓ Ready to import TensorFlow with GPU support\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e084985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TensorFlow GPU Detection & Diagnostics\n",
      "======================================================================\n",
      "TensorFlow version: 2.16.1\n",
      "\n",
      "Environment Variables:\n",
      "  CUDA_PATH:  C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\n",
      "  CUDNN_PATH: C:\\Program Files\\NVIDIA\\CUDNN\\v9.16\n",
      "\n",
      "TensorFlow Build Info:\n",
      "  CUDA Version: UNKNOWN\n",
      "  cuDNN Version: UNKNOWN\n",
      "\n",
      "Number of GPUs detected: 0\n",
      "\n",
      "⚠ WARNING: No GPUs detected!\n",
      "  System has NVIDIA RTX 3080 Ti but TensorFlow cannot find it.\n",
      "  Possible causes:\n",
      "    - CUDA 12.1 + cuDNN 12.9 version mismatch\n",
      "    - TensorFlow build requirements not met\n",
      "    - cuDNN DLL not in PATH\n",
      "  Falling back to CPU (much slower)\n",
      "\n",
      "All devices detected:\n",
      "  - /physical_device:CPU:0 (CPU)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Verify GPU/CUDA/cuDNN setup\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TensorFlow GPU Detection & Diagnostics\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Show current PATH\n",
    "print(\"\\nEnvironment Variables:\")\n",
    "print(f\"  CUDA_PATH:  {os.environ.get('CUDA_PATH', 'NOT SET')}\")\n",
    "print(f\"  CUDNN_PATH: {os.environ.get('CUDNN_PATH', 'NOT SET')}\")\n",
    "\n",
    "# Debug build configuration\n",
    "print(\"\\nTensorFlow Build Info:\")\n",
    "try:\n",
    "    build_info = tf.sysconfig.get_build_info()\n",
    "    print(f\"  CUDA Version: {build_info.get('cuda_version', 'UNKNOWN')}\")\n",
    "    print(f\"  cuDNN Version: {build_info.get('cudnn_version', 'UNKNOWN')}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not load build info: {e}\")\n",
    "\n",
    "# Check GPU detection\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nNumber of GPUs detected: {len(gpus)}\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"\\n✓ GPU(s) Available:\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  [{i}] {gpu.name}\")\n",
    "\n",
    "    # Enable GPU memory growth to avoid OOM errors\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"\\n✓ GPU memory growth enabled (dynamic allocation)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"  Warning: {e}\")\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: No GPUs detected!\")\n",
    "    print(\"  System has NVIDIA RTX 3080 Ti but TensorFlow cannot find it.\")\n",
    "    print(\"  Possible causes:\")\n",
    "    print(\"    - CUDA 12.1 + cuDNN 12.9 version mismatch\")\n",
    "    print(\"    - TensorFlow build requirements not met\")\n",
    "    print(\"    - cuDNN DLL not in PATH\")\n",
    "    print(\"  Falling back to CPU (much slower)\")\n",
    "\n",
    "# Show all devices\n",
    "print(f\"\\nAll devices detected:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(f\"  - {device.name} ({device.device_type})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c95a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Rev15: global config for GPU-accelerated XGBoost and fast boosters ===\n",
    "# Set these flags before training cells (Rev13/Rev14) so they pick up GPU / fast logic.\n",
    "\n",
    "USE_GPU_XGB = True      # Let Rev13 training try GPU ('gpu_hist') if available\n",
    "USE_XGB_FAST = True     # Let Rev14 fast per-target boosters train as well\n",
    "\n",
    "print(\"Rev15 config: USE_GPU_XGB =\", USE_GPU_XGB, \"| USE_XGB_FAST =\", USE_XGB_FAST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c314e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rev13 config: GPU & ensemble behaviour ===\n",
    "# Toggle GPU-accelerated XGBoost (will fall back to CPU if unavailable)\n",
    "USE_GPU_XGB = True\n",
    "\n",
    "# Ensemble weights when both best_model (real-only) and model_mc (augmented) exist.\n",
    "# (w_real, w_augmented) - should sum to 1.0\n",
    "ENSEMBLE_WEIGHTS = (0.3, 0.7)\n",
    "\n",
    "print(f\"Rev13 config -> USE_GPU_XGB={USE_GPU_XGB}, ENSEMBLE_WEIGHTS={ENSEMBLE_WEIGHTS}\")\n",
    "\n",
    "# === Rev14 config: fast GPU XGBoost + GA search ===\n",
    "\n",
    "# Enable fast per-target GPU XGBoost using DMatrix (in addition to existing sklearn pipelines)\n",
    "USE_XGB_FAST = True\n",
    "\n",
    "# Number of boosting rounds for fast models (per target)\n",
    "XGB_FAST_NUM_BOOST_ROUNDS = 400\n",
    "\n",
    "# Genetic Algorithm search config\n",
    "USE_GA_SEARCH = True\n",
    "GA_POP_SIZE = 120        # population size\n",
    "GA_NUM_GENERATIONS = 40  # how many generations\n",
    "GA_MUTATION_RATE = 0.12  # mutation probability per child\n",
    "GA_CROSSOVER_RATE = 0.85 # probability of crossover\n",
    "\n",
    "print(f\"Rev14 config -> USE_XGB_FAST={USE_XGB_FAST}, USE_GA_SEARCH={USE_GA_SEARCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Excel file. Ensure Lotto_2025-11-26.xlsx is in the same directory as this notebook.\n",
    "excel_path = \"Lotto_2025-11-26.xlsx\"\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "print(\"Data shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nColumns:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb252b",
   "metadata": {},
   "source": [
    "## Basic cleaning and helper columns\n",
    "\n",
    "We:\n",
    "\n",
    "- Ensure the winning number columns are numeric.\n",
    "- Convert helper columns like `From Last`, `Same As Day`, `Odd`, `Even` to numeric (if present).\n",
    "- Parse `Date` and add simple date features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winning number columns (targets)\n",
    "# In Lotto_2025-11-26.xlsx the first column is \"Winning Number 1\"\n",
    "# and the remaining winning numbers are in columns \"2\", \"3\", \"4\", \"5\", \"6\".\n",
    "number_cols = [\n",
    "    \"Winning Number 1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "]\n",
    "\n",
    "# Ensure numeric for winning numbers\n",
    "for col in number_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected column '{col}' not found in dataframe.\")\n",
    "\n",
    "# Helper columns that may exist\n",
    "helper_cols = [\"From Last\", \"Same As Day\", \"Odd\", \"Even\"]\n",
    "for col in helper_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Date handling\n",
    "if \"Date\" in df.columns:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df[\"Year\"] = df[\"Date\"].dt.year.fillna(0).astype(int)\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month.fillna(0).astype(int)\n",
    "    df[\"DayOfWeek\"] = df[\"Date\"].dt.dayofweek.fillna(0).astype(int)\n",
    "else:\n",
    "    df[\"Year\"] = 0\n",
    "    df[\"Month\"] = 0\n",
    "    df[\"DayOfWeek\"] = 0\n",
    "\n",
    "print(\"After basic cleaning:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d4379",
   "metadata": {},
   "source": [
    "## 5-number bucket features with named ranges\n",
    "\n",
    "We map numbers as follows (for NZ Lotto 1–40):\n",
    "\n",
    "- 1–5   → bucket index 0 → features: `bucket_1_5_count`, `bucket_1_5_present`\n",
    "- 6–10  → bucket index 1 → `bucket_6_10_count`, ...\n",
    "- 11–15 → bucket index 2\n",
    "- 16–20 → bucket index 3\n",
    "- 21–25 → bucket index 4\n",
    "- 26–30 → bucket index 5\n",
    "- 31–35 → bucket index 6\n",
    "- 36–40 → bucket index 7\n",
    "\n",
    "So you can immediately see which 5-number range each feature refers to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_bucket(num: float, bucket_size: int = 5) -> float:\n",
    "    \"\"\"Map a lotto number to a 0-based bucket index of size `bucket_size`.\n",
    "    Returns NaN for missing values.\n",
    "    \"\"\"\n",
    "    if pd.isna(num):\n",
    "        return np.nan\n",
    "    return int((int(num) - 1) // bucket_size)\n",
    "\n",
    "# Create per-number bucket columns (indices)\n",
    "for col in number_cols:\n",
    "    df[f\"{col}_bucket\"] = df[col].apply(num_to_bucket)\n",
    "\n",
    "bucket_cols = [f\"{col}_bucket\" for col in number_cols]\n",
    "max_bucket = int(df[bucket_cols].max().max())\n",
    "\n",
    "# Infer max actual number from data (e.g. 40)\n",
    "max_number = int(df[number_cols].max().max())\n",
    "bucket_size = 5\n",
    "\n",
    "# Build mapping from bucket index -> human-readable column names\n",
    "bucket_index_to_count_col = {}\n",
    "bucket_index_to_present_col = {}\n",
    "bucket_count_cols = []\n",
    "bucket_present_cols = []\n",
    "\n",
    "for i in range(max_bucket + 1):\n",
    "    low = i * bucket_size + 1\n",
    "    high = min((i + 1) * bucket_size, max_number)\n",
    "    count_name = f\"bucket_{low}_{high}_count\"\n",
    "    present_name = f\"bucket_{low}_{high}_present\"\n",
    "    bucket_index_to_count_col[i] = count_name\n",
    "    bucket_index_to_present_col[i] = present_name\n",
    "    bucket_count_cols.append(count_name)\n",
    "    bucket_present_cols.append(present_name)\n",
    "\n",
    "print(\"Bucket index to feature names:\")\n",
    "for i in range(max_bucket + 1):\n",
    "    print(i, \"->\", bucket_index_to_count_col[i], \",\", bucket_index_to_present_col[i])\n",
    "\n",
    "display(df[bucket_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b526d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bucket counts per draw using the named columns\n",
    "def bucket_count_row(row):\n",
    "    counts = np.zeros(max_bucket + 1, dtype=int)\n",
    "    buckets = row[bucket_cols].values\n",
    "    for b in buckets:\n",
    "        if not pd.isna(b):\n",
    "            b_int = int(b)\n",
    "            if 0 <= b_int <= max_bucket:\n",
    "                counts[b_int] += 1\n",
    "    # Map counts into named columns\n",
    "    data = {}\n",
    "    for i in range(max_bucket + 1):\n",
    "        data[bucket_index_to_count_col[i]] = counts[i]\n",
    "    return pd.Series(data, index=bucket_count_cols)\n",
    "\n",
    "df_bucket_counts = df.apply(bucket_count_row, axis=1)\n",
    "df = pd.concat([df, df_bucket_counts], axis=1)\n",
    "\n",
    "# Presence flags using named columns\n",
    "for i in range(max_bucket + 1):\n",
    "    count_col = bucket_index_to_count_col[i]\n",
    "    present_col = bucket_index_to_present_col[i]\n",
    "    df[present_col] = (df[count_col] > 0).astype(int)\n",
    "\n",
    "# Bucket energy (weighted sum of bucket indices by count)\n",
    "df[\"bucket_energy\"] = 0\n",
    "for i in range(max_bucket + 1):\n",
    "    count_col = bucket_index_to_count_col[i]\n",
    "    df[\"bucket_energy\"] += i * df[count_col]\n",
    "\n",
    "print(\"Bucket features created (named ranges):\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12df635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save expanded dataset with new features\n",
    "output_excel_path = \"Lotto_2025-11-26_Imputed.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "print(f\"Saved dataset with new features to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2a4fe",
   "metadata": {},
   "source": [
    "## Build feature matrix and target matrix\n",
    "\n",
    "- **Targets**: the six winning numbers as a 6D regression target.\n",
    "- **Features**: named bucket counts/presence, bucket energy, helper columns, and date parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = number_cols.copy()\n",
    "\n",
    "# bucket_count_cols and bucket_present_cols already defined with meaningful names\n",
    "candidate_feature_cols = (\n",
    "    bucket_count_cols\n",
    "    + bucket_present_cols\n",
    "    + [\"bucket_energy\", \"From Last\", \"Same As Day\", \"Odd\", \"Even\", \"Year\", \"Month\", \"DayOfWeek\"]\n",
    ")\n",
    "\n",
    "# Keep only columns that exist in df (in case some helper cols are missing)\n",
    "feature_cols = [c for c in candidate_feature_cols if c in df.columns]\n",
    "\n",
    "print(\"Using feature columns:\")\n",
    "print(feature_cols)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target matrix shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5e335",
   "metadata": {},
   "source": [
    "# === Rev13: XGBoost training on real data with optional GPU ===\n",
    "\n",
    "# Base XGBoost parameters\n",
    "xgb_params = dict(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",   # default CPU\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Try to enable GPU if configured\n",
    "if 'USE_GPU_XGB' in globals() and USE_GPU_XGB:\n",
    "    try:\n",
    "        import xgboost as xgb  # just to confirm GPU build is available\n",
    "        xgb_params[\"tree_method\"] = \"gpu_hist\"\n",
    "        xgb_params[\"predictor\"] = \"gpu_predictor\"\n",
    "        print(\"Using GPU-accelerated XGBoost (tree_method='gpu_hist').\")\n",
    "    except Exception as e:\n",
    "        print(\"GPU XGBoost not available, falling back to CPU 'hist'. Reason:\", e)\n",
    "\n",
    "xgb_reg = XGBRegressor(**xgb_params)\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"regressor\", MultiOutputRegressor(xgb_reg)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Use MSE as the scoring metric (negative for cross_validate)\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "test_scores = -cv_results[\"test_score\"]  # convert back to positive MSE\n",
    "print(\"Cross-validation MSE scores:\", test_scores)\n",
    "print(\"Mean CV MSE:\", np.mean(test_scores))\n",
    "\n",
    "best_model_index = np.argmin(test_scores)\n",
    "best_model = cv_results[\"estimator\"][best_model_index]\n",
    "print(\"Best model index:\", best_model_index)\n",
    "print(\"Best model trained (real draws only) and stored as 'best_model'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14228b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Rev14: optional fast per-target GPU XGBoost using DMatrix ===\n",
    "# This does NOT replace the existing sklearn-based models; it adds an extra\n",
    "# set of boosters (one per output) that we can use for analysis or GA fitness.\n",
    "\n",
    "fast_models = None\n",
    "fast_feature_names = None\n",
    "\n",
    "if 'USE_XGB_FAST' in globals() and USE_XGB_FAST:\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "\n",
    "        print(\"Training fast per-target XGBoost models (Rev14)...\")\n",
    "\n",
    "        # Ensure X and y are numpy arrays\n",
    "        X_np = X.values if hasattr(X, \"values\") else X\n",
    "        y_np = y.values if hasattr(y, \"values\") else y\n",
    "\n",
    "        n_targets = y_np.shape[1]\n",
    "        fast_models = []\n",
    "        fast_feature_names = list(feature_cols)\n",
    "\n",
    "        base_params = {\n",
    "            \"max_depth\": 4,\n",
    "            \"eta\": 0.05,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"seed\": 42,\n",
    "        }\n",
    "\n",
    "        # Try GPU\n",
    "        if 'USE_GPU_XGB' in globals() and USE_GPU_XGB:\n",
    "            base_params[\"tree_method\"] = \"gpu_hist\"\n",
    "            base_params[\"predictor\"] = \"gpu_predictor\"\n",
    "\n",
    "        num_boost_round = int(XGB_FAST_NUM_BOOST_ROUNDS) if \"XGB_FAST_NUM_BOOST_ROUNDS\" in globals() else 400\n",
    "\n",
    "        for t in range(n_targets):\n",
    "            print(f\"  Training fast model for target {t+1}/{n_targets}...\")\n",
    "            dtrain = xgb.DMatrix(X_np, label=y_np[:, t], feature_names=fast_feature_names)\n",
    "            booster = xgb.train(\n",
    "                params=base_params,\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round=num_boost_round,\n",
    "                verbose_eval=False,\n",
    "            )\n",
    "            fast_models.append(booster)\n",
    "\n",
    "        print(f\"Trained {len(fast_models)} fast XGBoost models.\")\n",
    "    except Exception as e:\n",
    "        print(\"Fast XGB training skipped due to error:\", e)\n",
    "        fast_models = None\n",
    "        fast_feature_names = None\n",
    "else:\n",
    "    print(\"USE_XGB_FAST is False; skipping fast XGBoost training for Rev14.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base XGBoost regressor\n",
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",  # change to 'gpu_hist' if you have GPU XGBoost installed\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"regressor\", MultiOutputRegressor(xgb_reg)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "test_scores = -cv_results[\"test_score\"]  # convert back to positive MSE\n",
    "print(\"Cross-validation MSE scores:\", test_scores)\n",
    "print(\"Mean CV MSE:\", np.mean(test_scores))\n",
    "\n",
    "best_model_index = np.argmin(test_scores)\n",
    "best_model = cv_results[\"estimator\"][best_model_index]\n",
    "print(\"Best model index:\", best_model_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f618e9",
   "metadata": {},
   "source": [
    "## Predicting from candidate draws\n",
    "\n",
    "To keep things simple, we:\n",
    "\n",
    "1. Generate a **candidate draw** (6 random numbers 1–40, no replacement).\n",
    "2. Build the same **bucket-based features** (with named ranges) for that draw.\n",
    "3. Use the best cross-validated model to predict a 6D output.\n",
    "4. Map predictions back into the 1–40 range (wrapping with modulo).\n",
    "\n",
    "This is more for exploration / \"pattern resonance\" than real prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ffc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Rev14: helper for fast model prediction given a single feature row ===\n",
    "\n",
    "def fast_models_predict(input_row):\n",
    "    \"\"\"Predict 6 outputs using the fast per-target boosters.\n",
    "    input_row: 1D array-like or single-row DataFrame in feature_cols order.\n",
    "    Returns a numpy array of shape (6,).\n",
    "    \"\"\"\n",
    "    if fast_models is None or fast_feature_names is None:\n",
    "        raise RuntimeError(\"fast_models are not trained or fast_feature_names missing.\")\n",
    "\n",
    "    import numpy as np\n",
    "    import xgboost as xgb\n",
    "\n",
    "    if hasattr(input_row, \"values\"):\n",
    "        arr = input_row.values.astype(float).reshape(1, -1)\n",
    "    else:\n",
    "        arr = np.asarray(input_row, dtype=float).reshape(1, -1)\n",
    "\n",
    "    dtest = xgb.DMatrix(arr, feature_names=fast_feature_names)\n",
    "\n",
    "    preds = []\n",
    "    for booster in fast_models:\n",
    "        preds.append(booster.predict(dtest)[0])\n",
    "    return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83505379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_from_draw(draw_numbers, feature_columns, max_bucket_local=None, bucket_size_local=5):\n",
    "    \"\"\"Build a one-row feature DataFrame for a candidate draw using the same\n",
    "    bucket logic and feature columns as the training data.\n",
    "    \"\"\"\n",
    "    draw_numbers = np.array(draw_numbers, dtype=int)\n",
    "    if max_bucket_local is None:\n",
    "        max_bucket_local = max_bucket\n",
    "\n",
    "    # bucket counts\n",
    "    counts = np.zeros(max_bucket_local + 1, dtype=int)\n",
    "    for n in draw_numbers:\n",
    "        b = num_to_bucket(n, bucket_size=bucket_size_local)\n",
    "        if 0 <= b <= max_bucket_local:\n",
    "            counts[b] += 1\n",
    "\n",
    "    row = {}\n",
    "\n",
    "    # bucket counts and presence using named columns\n",
    "    for i in range(max_bucket_local + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        present_col = bucket_index_to_present_col[i]\n",
    "        if count_col in feature_columns:\n",
    "            row[count_col] = counts[i]\n",
    "        if present_col in feature_columns:\n",
    "            row[present_col] = int(counts[i] > 0)\n",
    "\n",
    "    # bucket_energy\n",
    "    if \"bucket_energy\" in feature_columns:\n",
    "        row[\"bucket_energy\"] = sum(i * counts[i] for i in range(max_bucket_local + 1))\n",
    "\n",
    "    # draw-level stats (only if these columns exist in the model)\n",
    "    if \"draw_median\" in feature_columns:\n",
    "        row[\"draw_median\"] = float(np.median(draw_numbers))\n",
    "    if \"draw_mean\" in feature_columns:\n",
    "        row[\"draw_mean\"] = float(np.mean(draw_numbers))\n",
    "    if \"draw_min\" in feature_columns:\n",
    "        row[\"draw_min\"] = int(np.min(draw_numbers))\n",
    "    if \"draw_max\" in feature_columns:\n",
    "        row[\"draw_max\"] = int(np.max(draw_numbers))\n",
    "\n",
    "    # Odd / Even counts (if used as features)\n",
    "    if \"Odd\" in feature_columns:\n",
    "        row[\"Odd\"] = int((draw_numbers % 2 != 0).sum())\n",
    "    if \"Even\" in feature_columns:\n",
    "        row[\"Even\"] = int((draw_numbers % 2 == 0).sum())\n",
    "\n",
    "    # helper + date features (neutral defaults if present in training)\n",
    "    defaults = {\n",
    "        \"From Last\": 0,\n",
    "        \"Same As Day\": 0,\n",
    "        \"Year\": 0,\n",
    "        \"Month\": 0,\n",
    "        \"DayOfWeek\": 0,\n",
    "    }\n",
    "    for col, val in defaults.items():\n",
    "        if col in feature_columns and col not in row:\n",
    "            row[col] = val\n",
    "\n",
    "    # ensure all feature_columns exist\n",
    "    for col in feature_columns:\n",
    "        if col not in row:\n",
    "            row[col] = 0\n",
    "\n",
    "    return pd.DataFrame([row], columns=feature_columns)\n",
    "\n",
    "\n",
    "def sanitize_prediction(raw_pred, n_numbers=6, low=1, high=40):\n",
    "    \"\"\"Convert raw model outputs into a valid NZ Lotto line:\n",
    "    - Round to ints\n",
    "    - Wrap into [low, high] range\n",
    "    - Enforce uniqueness (no duplicates)\n",
    "    - Return sorted array of length n_numbers\n",
    "    \"\"\"\n",
    "    # Map floats to ints in the valid range\n",
    "    ints = ((np.round(raw_pred).astype(int) - 1) % high) + low\n",
    "    ints = np.clip(ints, low, high)\n",
    "\n",
    "    # Enforce uniqueness\n",
    "    uniq = np.unique(ints)\n",
    "\n",
    "    # If we have fewer than required, sample extra distinct numbers\n",
    "    if len(uniq) < n_numbers:\n",
    "        remaining = np.setdiff1d(np.arange(low, high + 1), uniq)\n",
    "        extra = np.random.choice(remaining, size=n_numbers - len(uniq), replace=False)\n",
    "        uniq = np.sort(np.concatenate([uniq, extra]))\n",
    "    # If we have more, truncate to the first n_numbers\n",
    "    elif len(uniq) > n_numbers:\n",
    "        uniq = np.sort(uniq)[:n_numbers]\n",
    "    else:\n",
    "        uniq = np.sort(uniq)\n",
    "\n",
    "    return uniq\n",
    "\n",
    "\n",
    "# Example: generate a few candidate draws and predict\n",
    "num_predictions = 5\n",
    "for i in range(num_predictions):\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "\n",
    "    # Prefer ensemble if both models exist; otherwise fall back gracefully\n",
    "    if \"best_model\" in globals() and \"model_mc\" in globals():\n",
    "        # Use configured ensemble weights if available, else default 0.3/0.7\n",
    "        if \"ENSEMBLE_WEIGHTS\" in globals():\n",
    "            w_base, w_aug = ENSEMBLE_WEIGHTS\n",
    "        else:\n",
    "            w_base, w_aug = 0.3, 0.7\n",
    "\n",
    "        pred_base = best_model.predict(input_df.values)[0]\n",
    "        pred_aug = model_mc.predict(input_df.values)[0]\n",
    "        pred = w_base * pred_base + w_aug * pred_aug\n",
    "        model_used = f\"ensemble (w_real={w_base:.2f}, w_aug={w_aug:.2f})\"\n",
    "    elif \"model_mc\" in globals():\n",
    "        pred = model_mc.predict(input_df.values)[0]\n",
    "        model_used = \"model_mc (augmented)\"\n",
    "    else:\n",
    "        pred = best_model.predict(input_df.values)[0]\n",
    "        model_used = \"best_model (original CV best)\"\n",
    "    predicted_numbers = sanitize_prediction(pred, n_numbers=6, low=1, high=40)\n",
    "\n",
    "    print(f\"Prediction set {i+1} using {model_used}:\")\n",
    "    print(\"  Candidate base numbers:\", candidate_numbers)\n",
    "    print(\"  Model predicted numbers:\", predicted_numbers)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf8fdb-dfa6-469a-8d0d-adf058526a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1bb139",
   "metadata": {},
   "source": [
    "## Monte Carlo Lotto Simulator, Bucket Energy & Delta Export\n",
    "\n",
    "This section:\n",
    "\n",
    "- Reuses the existing 5-number bucket logic.\n",
    "- Computes additional draw-level features like `draw_median`, `draw_mean`, `draw_min`, `draw_max`.\n",
    "- Visualises **bucket energy** and **median** over time.\n",
    "- Builds an **empirical + uniform blended Monte Carlo simulator** to generate many synthetic draws.\n",
    "- Computes the same bucket features for synthetic draws.\n",
    "- Optionally saves both real and synthetic feature tables to **Delta Lake** for ROAPI or other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing dataframe `df` and `number_cols` from earlier cells.\n",
    "# If your raw draws dataframe has a different name, adjust `df_draws` accordingly.\n",
    "df_draws = df  # alias for clarity\n",
    "\n",
    "number_cols = number_cols  # ensure we use the same target columns\n",
    "\n",
    "print(\"Using number columns:\", number_cols)\n",
    "\n",
    "def compute_bucket_features_for_draws(df_base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute bucket count/presence, bucket_energy and draw-level stats for each draw.\n",
    "    Also computes additional structural stats:\n",
    "    - draw_median / mean / min / max\n",
    "    - Odd / Even counts\n",
    "    - mean_gap / median_gap / std_gap between sorted numbers\n",
    "    - decade_transitions: how often we cross to a new decade band (1–10, 11–20, ...)\n",
    "    - gap_entropy: normalized entropy of the gap distribution\n",
    "    \"\"\"\n",
    "    df_feat = df_base.copy()\n",
    "\n",
    "    # Map each number to a bucket index using existing num_to_bucket\n",
    "    bucket_indices = df_feat[number_cols].applymap(num_to_bucket)\n",
    "\n",
    "    # Count per bucket into the named bucket_*_count columns\n",
    "    def row_to_bucket_counts(row):\n",
    "        counts = np.zeros(max_bucket + 1, dtype=int)\n",
    "        for b in row:\n",
    "            if pd.notnull(b):\n",
    "                b_int = int(b)\n",
    "                if 0 <= b_int <= max_bucket:\n",
    "                    counts[b_int] += 1\n",
    "        data = {}\n",
    "        for i in range(max_bucket + 1):\n",
    "            data[bucket_index_to_count_col[i]] = counts[i]\n",
    "        return pd.Series(data, index=bucket_count_cols)\n",
    "\n",
    "    df_counts = bucket_indices.apply(row_to_bucket_counts, axis=1)\n",
    "    df_feat[df_counts.columns] = df_counts\n",
    "\n",
    "    # Presence flags using named columns\n",
    "    for i in range(max_bucket + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        present_col = bucket_index_to_present_col[i]\n",
    "        if count_col in df_feat.columns:\n",
    "            df_feat[present_col] = (df_feat[count_col] > 0).astype(int)\n",
    "\n",
    "    # bucket_energy from bucket index * count\n",
    "    df_feat[\"bucket_energy\"] = 0\n",
    "    for i in range(max_bucket + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        if count_col in df_feat.columns:\n",
    "            df_feat[\"bucket_energy\"] += i * df_feat[count_col]\n",
    "\n",
    "    # Draw-level stats from the actual numbers\n",
    "    df_feat[\"draw_median\"] = df_feat[number_cols].median(axis=1)\n",
    "    df_feat[\"draw_mean\"] = df_feat[number_cols].mean(axis=1)\n",
    "    df_feat[\"draw_min\"] = df_feat[number_cols].min(axis=1)\n",
    "    df_feat[\"draw_max\"] = df_feat[number_cols].max(axis=1)\n",
    "\n",
    "    # Odd / Even counts\n",
    "    df_feat[\"Odd\"] = df_feat[number_cols].apply(lambda r: (r % 2 != 0).sum(), axis=1)\n",
    "    df_feat[\"Even\"] = df_feat[number_cols].apply(lambda r: (r % 2 == 0).sum(), axis=1)\n",
    "\n",
    "    # Extra line-level structural stats: gaps, decade transitions, gap entropy\n",
    "    def compute_line_extra_stats(row):\n",
    "        vals = row.values.astype(float)\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "        if len(vals) == 0:\n",
    "            return pd.Series({\n",
    "                \"mean_gap\": np.nan,\n",
    "                \"median_gap\": np.nan,\n",
    "                \"std_gap\": np.nan,\n",
    "                \"decade_transitions\": np.nan,\n",
    "                \"gap_entropy\": np.nan,\n",
    "            })\n",
    "        vals_sorted = np.sort(vals)\n",
    "        if len(vals_sorted) > 1:\n",
    "            gaps = np.diff(vals_sorted)\n",
    "        else:\n",
    "            gaps = np.array([0.0])\n",
    "\n",
    "        mean_gap = float(np.mean(gaps))\n",
    "        median_gap = float(np.median(gaps))\n",
    "        std_gap = float(np.std(gaps, ddof=0))\n",
    "\n",
    "        # decade bands: 1–10 -> 0, 11–20 -> 1, etc.\n",
    "        decades = ((vals_sorted - 1) // 10).astype(int)\n",
    "        if len(decades) > 1:\n",
    "            decade_transitions = int(np.count_nonzero(np.diff(decades) != 0))\n",
    "        else:\n",
    "            decade_transitions = 0\n",
    "\n",
    "        # gap entropy (normalized)\n",
    "        if len(gaps) > 0:\n",
    "            uniq, counts = np.unique(gaps, return_counts=True)\n",
    "            probs = counts.astype(float) / counts.sum()\n",
    "            ent = -np.sum(probs * np.log(probs))\n",
    "            if len(probs) > 1:\n",
    "                gap_entropy = float(ent / np.log(len(probs)))\n",
    "            else:\n",
    "                gap_entropy = 0.0\n",
    "        else:\n",
    "            gap_entropy = 0.0\n",
    "\n",
    "        return pd.Series({\n",
    "            \"mean_gap\": mean_gap,\n",
    "            \"median_gap\": median_gap,\n",
    "            \"std_gap\": std_gap,\n",
    "            \"decade_transitions\": float(decade_transitions),\n",
    "            \"gap_entropy\": gap_entropy,\n",
    "        })\n",
    "\n",
    "    extra = df_feat[number_cols].apply(compute_line_extra_stats, axis=1)\n",
    "    df_feat[extra.columns] = extra\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "df_real_feat = compute_bucket_features_for_draws(df_draws)\n",
    "print(\"Real feature table shape:\", df_real_feat.shape)\n",
    "df_real_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations: bucket_energy & draw_median over time, plus distributions\n",
    "x_axis = df_real_feat[\"Date\"] if \"Date\" in df_real_feat.columns else df_real_feat.index\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_axis, df_real_feat[\"bucket_energy\"])\n",
    "plt.title(\"Bucket Energy Over Time (Real Draws)\")\n",
    "plt.xlabel(\"Draw\")\n",
    "plt.ylabel(\"Bucket Energy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_axis, df_real_feat[\"draw_median\"])\n",
    "plt.title(\"Draw Median Over Time (Real Draws)\")\n",
    "plt.xlabel(\"Draw\")\n",
    "plt.ylabel(\"Median of Drawn Numbers\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_real_feat[\"bucket_energy\"], bins=20)\n",
    "plt.title(\"Distribution of Bucket Energy (Real Draws)\")\n",
    "plt.xlabel(\"Bucket Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "avg_counts = df_real_feat[bucket_count_cols].mean()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(range(len(avg_counts)), avg_counts.values)\n",
    "plt.xticks(range(len(avg_counts)), avg_counts.index, rotation=45)\n",
    "plt.title(\"Average Count per 5-Number Bucket (Real Draws)\")\n",
    "plt.ylabel(\"Avg Count per Draw\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical distribution of numbers from real draws\n",
    "def compute_empirical_probs(df_base: pd.DataFrame, number_columns) -> pd.Series:\n",
    "    nums = df_base[number_columns].values.ravel()\n",
    "    values, counts = np.unique(nums, return_counts=True)\n",
    "    n_min = int(nums.min())\n",
    "    n_max = int(nums.max())\n",
    "    all_numbers = np.arange(n_min, n_max + 1)\n",
    "\n",
    "    freq = pd.Series(0, index=all_numbers, dtype=float)\n",
    "    freq.loc[values] = counts\n",
    "    p_emp = freq / freq.sum()\n",
    "    return p_emp\n",
    "\n",
    "p_empirical = compute_empirical_probs(df_draws, number_cols)\n",
    "p_uniform = pd.Series(1.0 / len(p_empirical), index=p_empirical.index, dtype=float)\n",
    "\n",
    "# Blend empirical with uniform so we expand the observed pattern distribution\n",
    "alpha = 0.7  # 70% empirical, 30% uniform\n",
    "p_blended = alpha * p_empirical + (1 - alpha) * p_uniform\n",
    "p_blended = p_blended / p_blended.sum()\n",
    "\n",
    "print(\"First few blended probabilities:\")\n",
    "print(p_blended.head())\n",
    "\n",
    "def simulate_single_draw(draw_size=6, probs: pd.Series = p_blended):\n",
    "    \"\"\"Simulate one lotto draw by sampling without replacement from the blended distribution.\"\"\"\n",
    "    numbers = probs.index.to_numpy()\n",
    "    p = probs.values\n",
    "    sample = np.random.choice(numbers, size=draw_size, replace=False, p=p)\n",
    "    return np.sort(sample)\n",
    "\n",
    "def simulate_dataset(n_draws=100_000, draw_size=6, probs: pd.Series = p_blended):\n",
    "    draws = [simulate_single_draw(draw_size, probs) for _ in range(n_draws)]\n",
    "    df_sim = pd.DataFrame(draws, columns=number_cols[:draw_size])\n",
    "    df_sim[\"SimDrawID\"] = np.arange(1, n_draws + 1)\n",
    "    # Synthetic dates purely for plotting/ordering\n",
    "    df_sim[\"SimDate\"] = pd.date_range(\"2000-01-01\", periods=n_draws, freq=\"D\")\n",
    "    return df_sim\n",
    "\n",
    "N_SYNTH_DRAWS = 50_000  # adjust as you like\n",
    "df_synth = simulate_dataset(N_SYNTH_DRAWS)\n",
    "print(\"Synthetic draws shape:\", df_synth.shape)\n",
    "df_synth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the same bucket features for synthetic draws\n",
    "df_synth_feat = compute_bucket_features_for_draws(df_synth)\n",
    "\n",
    "print(\"Average bucket counts (real):\")\n",
    "print(df_real_feat[bucket_count_cols].mean().round(3))\n",
    "\n",
    "print(\"\\nAverage bucket counts (synthetic):\")\n",
    "print(df_synth_feat[bucket_count_cols].mean().round(3))\n",
    "\n",
    "# Optional: synthetic bucket energy distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_synth_feat[\"bucket_energy\"], bins=20)\n",
    "plt.title(\"Distribution of Bucket Energy (Synthetic Draws)\")\n",
    "plt.xlabel(\"Bucket Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a629b",
   "metadata": {},
   "source": [
    "## Delta Export, Monte Carlo-Augmented Training, and Lotto Number Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd00644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Delta Lake export for real + synthetic feature tables\n",
    "try:\n",
    "    from deltalake import write_deltalake\n",
    "    import pyarrow as pa\n",
    "    HAS_DELTALAKE = True\n",
    "except ImportError:\n",
    "    HAS_DELTALAKE = False\n",
    "    print(\"Warning: 'deltalake' or 'pyarrow' not installed; skipping Delta writes.\")\n",
    "    print(\"Install with: pip install deltalake pyarrow\")\n",
    "\n",
    "delta_base = Path(\"delta_lotto\")\n",
    "delta_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if HAS_DELTALAKE:\n",
    "    real_delta_path = delta_base / \"real_features\"\n",
    "    synth_delta_path = delta_base / \"synthetic_features\"\n",
    "\n",
    "    # Convert pandas DataFrames to Arrow tables explicitly\n",
    "    real_table = pa.Table.from_pandas(df_real_feat, preserve_index=False)\n",
    "    synth_table = pa.Table.from_pandas(df_synth_feat, preserve_index=False)\n",
    "\n",
    "    print(f\"Writing real feature table to Delta: {real_delta_path}\")\n",
    "    write_deltalake(str(real_delta_path), real_table, mode=\"overwrite\")\n",
    "\n",
    "    print(f\"Writing synthetic feature table to Delta: {synth_delta_path}\")\n",
    "    write_deltalake(str(synth_delta_path), synth_table, mode=\"overwrite\")\n",
    "\n",
    "    print(\"Delta export complete.\")\n",
    "else:\n",
    "    print(\"Delta export skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c107504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain XGBoost on augmented dataset: real + synthetic Monte Carlo draws\n",
    "# We reuse:\n",
    "# - feature_cols: feature column list used originally\n",
    "# - target_cols: the six winning-number columns\n",
    "# - model: the Pipeline(imputer + MultiOutputRegressor(XGBRegressor))\n",
    "\n",
    "# Ensure we have the target columns present in both real and synthetic feature tables\n",
    "missing_targets_real = [c for c in target_cols if c not in df_real_feat.columns]\n",
    "missing_targets_synth = [c for c in target_cols if c not in df_synth_feat.columns]\n",
    "\n",
    "if missing_targets_real or missing_targets_synth:\n",
    "    print(\"Warning: some target columns are missing in real or synthetic tables.\")\n",
    "    print(\"Missing in real:\", missing_targets_real)\n",
    "    print(\"Missing in synthetic:\", missing_targets_synth)\n",
    "else:\n",
    "    # Build augmented dataframe with just the columns we need\n",
    "    cols_needed = feature_cols + target_cols\n",
    "\n",
    "    # Ensure synthetic feature table has all required columns; fill missing with 0\n",
    "    for col in cols_needed:\n",
    "        if col not in df_synth_feat.columns:\n",
    "            df_synth_feat[col] = 0\n",
    "\n",
    "    # Also ensure real feature table has all required columns (defensive)\n",
    "    for col in cols_needed:\n",
    "        if col not in df_real_feat.columns:\n",
    "            df_real_feat[col] = 0\n",
    "\n",
    "    df_real_aug = df_real_feat[cols_needed].copy()\n",
    "    df_synth_aug = df_synth_feat[cols_needed].copy()\n",
    "\n",
    "    df_aug = pd.concat([df_real_aug, df_synth_aug], axis=0, ignore_index=True)\n",
    "    print(\"Augmented dataset shape:\", df_aug.shape)\n",
    "\n",
    "    X_aug = df_aug[feature_cols].values\n",
    "    y_aug = df_aug[target_cols].values\n",
    "\n",
    "    print(\"Augmented feature matrix shape:\", X_aug.shape)\n",
    "    print(\"Augmented target matrix shape:\", y_aug.shape)\n",
    "\n",
    "    # Fit a new model on the full augmented dataset (no extra CV here)\n",
    "    model_mc = model.fit(X_aug, y_aug)\n",
    "    print(\"Monte Carlo-augmented XGBoost model trained and stored as 'model_mc'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example Lotto predictions using the current model (prefers model_mc if available)\n",
    "num_predictions = 5\n",
    "for i in range(num_predictions):\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "\n",
    "    if \"model_mc\" in globals():\n",
    "        pred = model_mc.predict(input_df.values)[0]\n",
    "        model_used = \"model_mc (augmented)\"\n",
    "    else:\n",
    "        pred = best_model.predict(input_df.values)[0]\n",
    "        model_used = \"best_model (original CV best)\"\n",
    "\n",
    "    predicted_numbers = sanitize_prediction(pred, n_numbers=6, low=1, high=40)\n",
    "\n",
    "    print(f\"Prediction set {i+1} using {model_used}:\")\n",
    "    print(\"  Candidate base numbers:\", candidate_numbers)\n",
    "    print(\"  Model predicted numbers:\", predicted_numbers)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e446aae",
   "metadata": {},
   "source": [
    "## Pattern Resonance Scoring & Extra Visualisations\n",
    "\n",
    "This section adds:\n",
    "- A **pattern resonance score** for any predicted Lotto line, comparing it to historical draw structure.\n",
    "- Extra plots comparing **real vs synthetic** distributions and highlighting where model-generated lines sit in feature space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da649b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Pattern resonance helpers ---\n",
    "\n",
    "def line_to_features(line_numbers, max_bucket_local=None, bucket_size_local=5):\n",
    "    \"\"\"Compute a feature dict for a single line of numbers:\n",
    "\n",
    "    - bucket_counts (per 5-number bucket)\n",
    "    - bucket_energy\n",
    "    - draw_median\n",
    "    - Odd / Even counts\n",
    "    - mean_gap / median_gap / std_gap between sorted numbers\n",
    "    - decade_transitions across 10-number bands (1–10, 11–20, ...)\n",
    "    - gap_entropy (normalized entropy of the gap distribution)\n",
    "    \"\"\"\n",
    "    line_numbers = np.array(line_numbers, dtype=int)\n",
    "    if max_bucket_local is None:\n",
    "        max_bucket_local = max_bucket\n",
    "\n",
    "    # bucket counts\n",
    "    counts = np.zeros(max_bucket_local + 1, dtype=int)\n",
    "    for n in line_numbers:\n",
    "        b = num_to_bucket(n, bucket_size=bucket_size_local)\n",
    "        if 0 <= b <= max_bucket_local:\n",
    "            counts[b] += 1\n",
    "\n",
    "    feats = {}\n",
    "    feats[\"bucket_counts\"] = counts\n",
    "    feats[\"bucket_energy\"] = sum(i * counts[i] for i in range(max_bucket_local + 1))\n",
    "    feats[\"draw_median\"] = float(np.median(line_numbers))\n",
    "    feats[\"Odd\"] = int((line_numbers % 2 != 0).sum())\n",
    "    feats[\"Even\"] = int((line_numbers % 2 == 0).sum())\n",
    "\n",
    "    # Gap-based features\n",
    "    line_sorted = np.sort(line_numbers)\n",
    "    if len(line_sorted) > 1:\n",
    "        gaps = np.diff(line_sorted.astype(float))\n",
    "    else:\n",
    "        gaps = np.array([0.0])\n",
    "\n",
    "    feats[\"mean_gap\"] = float(np.mean(gaps))\n",
    "    feats[\"median_gap\"] = float(np.median(gaps))\n",
    "    feats[\"std_gap\"] = float(np.std(gaps, ddof=0))\n",
    "\n",
    "    # Decade transitions: 1–10 -> 0, 11–20 -> 1, etc.\n",
    "    decades = ((line_sorted - 1) // 10).astype(int)\n",
    "    if len(decades) > 1:\n",
    "        feats[\"decade_transitions\"] = float(np.count_nonzero(np.diff(decades) != 0))\n",
    "    else:\n",
    "        feats[\"decade_transitions\"] = 0.0\n",
    "\n",
    "    # Gap entropy (normalized)\n",
    "    if len(gaps) > 0:\n",
    "        uniq, counts_g = np.unique(gaps, return_counts=True)\n",
    "        probs = counts_g.astype(float) / counts_g.sum()\n",
    "        ent = -np.sum(probs * np.log(probs))\n",
    "        if len(probs) > 1:\n",
    "            feats[\"gap_entropy\"] = float(ent / np.log(len(probs)))\n",
    "        else:\n",
    "            feats[\"gap_entropy\"] = 0.0\n",
    "    else:\n",
    "        feats[\"gap_entropy\"] = 0.0\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def compute_historical_profiles(df_real_feat, bucket_count_cols):\n",
    "    \"\"\"Precompute historical reference statistics from real draws.\"\"\"\n",
    "    hist = {}\n",
    "    # Average bucket counts per draw\n",
    "    hist[\"mean_bucket_counts\"] = df_real_feat[bucket_count_cols].mean().values\n",
    "    hist[\"std_bucket_counts\"] = df_real_feat[bucket_count_cols].std(ddof=0).values\n",
    "\n",
    "    # bucket_energy stats\n",
    "    hist[\"mean_bucket_energy\"] = df_real_feat[\"bucket_energy\"].mean()\n",
    "    hist[\"std_bucket_energy\"] = df_real_feat[\"bucket_energy\"].std(ddof=0)\n",
    "\n",
    "    # draw_median stats (if present)\n",
    "    if \"draw_median\" in df_real_feat.columns:\n",
    "        hist[\"mean_draw_median\"] = df_real_feat[\"draw_median\"].mean()\n",
    "        hist[\"std_draw_median\"] = df_real_feat[\"draw_median\"].std(ddof=0)\n",
    "    else:\n",
    "        hist[\"mean_draw_median\"] = None\n",
    "        hist[\"std_draw_median\"] = None\n",
    "\n",
    "    # Odd/Even stats if available\n",
    "    if \"Odd\" in df_real_feat.columns and \"Even\" in df_real_feat.columns:\n",
    "        hist[\"mean_odd\"] = df_real_feat[\"Odd\"].mean()\n",
    "        hist[\"mean_even\"] = df_real_feat[\"Even\"].mean()\n",
    "    else:\n",
    "        hist[\"mean_odd\"] = None\n",
    "        hist[\"mean_even\"] = None\n",
    "\n",
    "    # Gap / decade / entropy stats if available\n",
    "    for col in [\"mean_gap\", \"median_gap\", \"std_gap\", \"decade_transitions\", \"gap_entropy\"]:\n",
    "        if col in df_real_feat.columns:\n",
    "            hist[f\"mean_{col}\"] = df_real_feat[col].mean()\n",
    "            hist[f\"std_{col}\"] = df_real_feat[col].std(ddof=0)\n",
    "        else:\n",
    "            hist[f\"mean_{col}\"] = None\n",
    "            hist[f\"std_{col}\"] = None\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def pattern_resonance_score(line_numbers, hist_profile, bucket_count_cols):\n",
    "    \"\"\"Compute a 0–1 'pattern resonance' score indicating how Lotto-like\n",
    "    a given line is, compared to historical patterns.\n",
    "\n",
    "    Uses:\n",
    "    - Bucket count distance\n",
    "    - Bucket energy distance (z-score)\n",
    "    - Median distance (z-score)\n",
    "    - Odd/even balance\n",
    "    - Gap structure similarity (mean_gap, std_gap)\n",
    "    - Decade transition similarity\n",
    "    - Gap entropy similarity\n",
    "    \"\"\"\n",
    "    feats = line_to_features(line_numbers)\n",
    "    counts = feats[\"bucket_counts\"].astype(float)\n",
    "\n",
    "    # --- Bucket count score (Euclidean distance vs mean, normalized) ---\n",
    "    mean_counts = hist_profile[\"mean_bucket_counts\"]\n",
    "    std_counts = hist_profile[\"std_bucket_counts\"]\n",
    "    if std_counts is not None:\n",
    "        diff = (counts - mean_counts) / (std_counts + 1e-6)\n",
    "        dist = np.linalg.norm(diff)\n",
    "        bucket_score = np.exp(-dist / (2.0 * len(counts) ** 0.5))\n",
    "    else:\n",
    "        bucket_score = 1.0\n",
    "\n",
    "    # --- Bucket energy score ---\n",
    "    if hist_profile[\"std_bucket_energy\"] not in (None, 0):\n",
    "        z_energy = (feats[\"bucket_energy\"] - hist_profile[\"mean_bucket_energy\"]) / hist_profile[\"std_bucket_energy\"]\n",
    "        energy_score = np.exp(-abs(z_energy))\n",
    "    else:\n",
    "        energy_score = 1.0\n",
    "\n",
    "    # --- Median score ---\n",
    "    if hist_profile[\"mean_draw_median\"] is not None and hist_profile[\"std_draw_median\"] not in (None, 0):\n",
    "        z_median = (feats[\"draw_median\"] - hist_profile[\"mean_draw_median\"]) / hist_profile[\"std_draw_median\"]\n",
    "        median_score = np.exp(-abs(z_median))\n",
    "    else:\n",
    "        median_score = 1.0\n",
    "\n",
    "    # --- Odd/Even score ---\n",
    "    if hist_profile[\"mean_odd\"] is not None and hist_profile[\"mean_even\"] is not None:\n",
    "        odd_diff = abs(feats[\"Odd\"] - hist_profile[\"mean_odd\"])\n",
    "        even_diff = abs(feats[\"Even\"] - hist_profile[\"mean_even\"])\n",
    "        # Assume typical odd/even deviations of ~1.5 are fine\n",
    "        odd_even_score = np.exp(-(odd_diff + even_diff) / 3.0)\n",
    "    else:\n",
    "        odd_even_score = 1.0\n",
    "\n",
    "    # --- Gap structure score (mean_gap, std_gap) ---\n",
    "    gap_scores = []\n",
    "    for col in [\"mean_gap\", \"std_gap\"]:\n",
    "        mean_key = f\"mean_{col}\"\n",
    "        std_key = f\"std_{col}\"\n",
    "        if hist_profile.get(mean_key) is not None and hist_profile.get(std_key) not in (None, 0):\n",
    "            z = (feats[col] - hist_profile[mean_key]) / hist_profile[std_key]\n",
    "            gap_scores.append(np.exp(-abs(z)))\n",
    "    if gap_scores:\n",
    "        gap_score = float(np.prod(gap_scores) ** (1.0 / len(gap_scores)))\n",
    "    else:\n",
    "        gap_score = 1.0\n",
    "\n",
    "    # --- Decade transition score ---\n",
    "    mean_dec = hist_profile.get(\"mean_decade_transitions\")\n",
    "    std_dec = hist_profile.get(\"std_decade_transitions\")\n",
    "    if mean_dec is not None and std_dec not in (None, 0):\n",
    "        z_dec = (feats[\"decade_transitions\"] - mean_dec) / std_dec\n",
    "        decade_score = float(np.exp(-abs(z_dec)))\n",
    "    else:\n",
    "        decade_score = 1.0\n",
    "\n",
    "    # --- Gap entropy score ---\n",
    "    mean_ge = hist_profile.get(\"mean_gap_entropy\")\n",
    "    std_ge = hist_profile.get(\"std_gap_entropy\")\n",
    "    if mean_ge is not None and std_ge not in (None, 0):\n",
    "        z_ge = (feats[\"gap_entropy\"] - mean_ge) / std_ge\n",
    "        entropy_score = float(np.exp(-abs(z_ge)))\n",
    "    else:\n",
    "        entropy_score = 1.0\n",
    "\n",
    "    # Combine scores (geometric mean for balance)\n",
    "    scores = np.array([bucket_score, energy_score, median_score, odd_even_score,\n",
    "                       gap_score, decade_score, entropy_score])\n",
    "    pattern_score = float(np.prod(scores) ** (1.0 / len(scores)))\n",
    "    return pattern_score, {\n",
    "        \"bucket_score\": float(bucket_score),\n",
    "        \"energy_score\": float(energy_score),\n",
    "        \"median_score\": float(median_score),\n",
    "        \"odd_even_score\": float(odd_even_score),\n",
    "        \"gap_score\": float(gap_score),\n",
    "        \"decade_score\": float(decade_score),\n",
    "        \"entropy_score\": float(entropy_score),\n",
    "    }\n",
    "\n",
    "\n",
    "# Precompute historical profile once, if not already done\n",
    "historical_profile = compute_historical_profiles(df_real_feat, bucket_count_cols)\n",
    "print(\"Historical pattern profile computed (extended with gap/decade stats).\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931edc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Extra visualisations ---\n",
    "\n",
    "# 1) Real vs synthetic average bucket counts\n",
    "if \"df_synth_feat\" in globals():\n",
    "    real_avg_counts = df_real_feat[bucket_count_cols].mean()\n",
    "    synth_avg_counts = df_synth_feat[bucket_count_cols].mean()\n",
    "\n",
    "    x = np.arange(len(bucket_count_cols))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(x - width/2, real_avg_counts.values, width, label=\"Real\")\n",
    "    plt.bar(x + width/2, synth_avg_counts.values, width, label=\"Synthetic MC\")\n",
    "    plt.xticks(x, bucket_count_cols, rotation=45)\n",
    "    plt.ylabel(\"Avg count per draw\")\n",
    "    plt.title(\"Average Bucket Counts: Real vs Monte Carlo Synthetic\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 2) Bucket energy vs median: real vs synthetic\n",
    "plt.figure(figsize=(6, 5))\n",
    "if \"draw_median\" in df_real_feat.columns:\n",
    "    plt.scatter(df_real_feat[\"draw_median\"], df_real_feat[\"bucket_energy\"], alpha=0.3, label=\"Real\")\n",
    "    if \"df_synth_feat\" in globals() and \"draw_median\" in df_synth_feat.columns:\n",
    "        plt.scatter(df_synth_feat[\"draw_median\"], df_synth_feat[\"bucket_energy\"], alpha=0.2, label=\"Synthetic\", marker=\"x\")\n",
    "    plt.xlabel(\"Draw Median\")\n",
    "    plt.ylabel(\"Bucket Energy\")\n",
    "    plt.title(\"Bucket Energy vs Draw Median (Real vs Synthetic)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 3) Example: score and visualise the last N generated prediction lines\n",
    "example_lines = [\n",
    "    np.array([3, 8, 16, 20, 23, 28]),\n",
    "    np.array([3, 12, 18, 26, 29, 33]),\n",
    "    np.array([2, 4, 8, 13, 18, 33]),\n",
    "    np.array([8, 16, 19, 23, 33, 38]),\n",
    "    np.array([3, 6, 9, 19, 37, 39]),\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for line in example_lines:\n",
    "    s, breakdown = pattern_resonance_score(line, historical_profile, bucket_count_cols)\n",
    "    scores.append((line, s, breakdown))\n",
    "\n",
    "print(\"Example pattern resonance scores:\")\n",
    "for line, s, breakdown in scores:\n",
    "    print(f\"Line {line.tolist()} -> score={s:.3f}, components={breakdown}\")\n",
    "\n",
    "# Bar plot of overall scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "labels = [f\"L{i+1}\" for i in range(len(scores))]\n",
    "vals = [s for (_, s, _) in scores]\n",
    "plt.bar(labels, vals)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel(\"Pattern Resonance Score\")\n",
    "plt.title(\"Pattern Resonance Scores for Example Lines\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af868e7a",
   "metadata": {},
   "source": [
    "## Bulk Generation & Top-N Pattern-Resonant Predictions\n",
    "\n",
    "This section:\n",
    "- Generates a large number of model-based Lotto lines (e.g. 10,000)\n",
    "- Computes the pattern resonance score for each line\n",
    "- Sorts them and shows the top-N most Lotto-like lines according to historical structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_model_line(feature_cols, use_model_mc=True):\n",
    "    \"\"\"Generate a single Lotto line using the current model and sanitiser.\"\"\"\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "\n",
    "    # Decide how to predict this line:\n",
    "    # - If both models exist and use_model_mc=True, use ensemble (real + augmented)\n",
    "    # - If only model_mc exists and use_model_mc=True, use augmented model\n",
    "    # - Otherwise, fall back to best_model (real-only)\n",
    "    if \"best_model\" in globals() and \"model_mc\" in globals():\n",
    "        if use_model_mc:\n",
    "            if \"ENSEMBLE_WEIGHTS\" in globals():\n",
    "                w_base, w_aug = ENSEMBLE_WEIGHTS\n",
    "            else:\n",
    "                w_base, w_aug = 0.3, 0.7\n",
    "            pred_base = best_model.predict(input_df.values)[0]\n",
    "            pred_aug = model_mc.predict(input_df.values)[0]\n",
    "            pred = w_base * pred_base + w_aug * pred_aug\n",
    "        else:\n",
    "            pred = best_model.predict(input_df.values)[0]\n",
    "    elif use_model_mc and \"model_mc\" in globals():\n",
    "        pred = model_mc.predict(input_df.values)[0]\n",
    "    else:\n",
    "        pred = best_model.predict(input_df.values)[0]\n",
    "    line = sanitize_prediction(pred, n_numbers=6, low=1, high=40)\n",
    "    return line\n",
    "\n",
    "\n",
    "def bulk_generate_and_score(\n",
    "    n_samples=10000,\n",
    "    top_n=20,\n",
    "    use_model_mc=True,\n",
    "    verbose_every=1000\n",
    "):\n",
    "    \"\"\"Generate many model-based Lotto lines, score them, and return Top-N\n",
    "    UNIQUE lines sorted by pattern resonance and frequency.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Generate one Lotto line using the ML model\n",
    "        line = generate_model_line(feature_cols, use_model_mc=use_model_mc)\n",
    "\n",
    "        # Score pattern resonance\n",
    "        score, breakdown = pattern_resonance_score(line, historical_profile, bucket_count_cols)\n",
    "\n",
    "        records.append({\n",
    "            \"line\": line,\n",
    "            \"score\": score,\n",
    "            \"bucket_score\": breakdown[\"bucket_score\"],\n",
    "            \"energy_score\": breakdown[\"energy_score\"],\n",
    "            \"median_score\": breakdown[\"median_score\"],\n",
    "            \"odd_even_score\": breakdown[\"odd_even_score\"],\n",
    "        })\n",
    "\n",
    "        if verbose_every and (i + 1) % verbose_every == 0:\n",
    "            print(f\"Generated and scored {i+1} lines...\")\n",
    "\n",
    "    df_scores = pd.DataFrame(records)\n",
    "\n",
    "    # Make a dedupe key: \"3,8,16,20,23,28\"\n",
    "    df_scores[\"line_str\"] = df_scores[\"line\"].apply(lambda arr: \",\".join(map(str, arr)))\n",
    "\n",
    "    # Aggregate unique line stats\n",
    "    grouped = (\n",
    "        df_scores\n",
    "        .groupby(\"line_str\")\n",
    "        .agg(\n",
    "            line=(\"line\", \"first\"),\n",
    "            score=(\"score\", \"max\"),\n",
    "            bucket_score=(\"bucket_score\", \"max\"),\n",
    "            energy_score=(\"energy_score\", \"max\"),\n",
    "            median_score=(\"median_score\", \"max\"),\n",
    "            odd_even_score=(\"odd_even_score\", \"max\"),\n",
    "            frequency=(\"line_str\", \"count\"),\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Sort by score desc, then frequency desc\n",
    "    df_sorted = grouped.sort_values(\n",
    "        by=[\"score\", \"frequency\"],\n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nTop {top_n} UNIQUE pattern-resonant lines out of {n_samples} samples:\\n\")\n",
    "\n",
    "    for idx in range(min(top_n, len(df_sorted))):\n",
    "        row = df_sorted.iloc[idx]\n",
    "        print(\n",
    "            f\"Rank {idx+1}: line={row['line'].tolist()}  \"\n",
    "            f\"score={row['score']:.3f}  freq={row['frequency']}  \"\n",
    "            f\"(bucket={row['bucket_score']:.3f}, \"\n",
    "            f\"energy={row['energy_score']:.3f}, \"\n",
    "            f\"median={row['median_score']:.3f}, \"\n",
    "            f\"odd_even={row['odd_even_score']:.3f})\"\n",
    "        )\n",
    "\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4e8a8-2836-4ef6-99f4-4857eaa9b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topk = bulk_generate_and_score(\n",
    "    n_samples=5000,\n",
    "    top_n=20,\n",
    "    use_model_mc=True,\n",
    "    verbose_every=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7e35f",
   "metadata": {},
   "source": [
    "## Extra Analysis of Top Pattern-Resonant Lines\n",
    "\n",
    "These plots help understand how the top-ranked lines relate to historical structure:\n",
    "- Histogram of resonance scores for the unique top lines\n",
    "- Resonance vs line median\n",
    "- Resonance vs bucket energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure df_topk exists\n",
    "if 'df_topk' in globals() and not df_topk.empty:\n",
    "    # 1) Histogram of resonance scores\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(df_topk[\"score\"], bins=15)\n",
    "    plt.xlabel(\"Pattern Resonance Score\")\n",
    "    plt.ylabel(\"Frequency (unique lines)\")\n",
    "    plt.title(\"Distribution of Pattern Resonance Scores (Top Unique Lines)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Score vs median for each top line\n",
    "    medians = []\n",
    "    scores = df_topk[\"score\"].values\n",
    "\n",
    "    for line in df_topk[\"line\"]:\n",
    "        line_arr = np.array(line, dtype=int)\n",
    "        medians.append(np.median(line_arr))\n",
    "\n",
    "    medians = np.array(medians)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(medians, scores)\n",
    "    plt.xlabel(\"Line Median\")\n",
    "    plt.ylabel(\"Pattern Resonance Score\")\n",
    "    plt.title(\"Resonance Score vs Median of Top Lines\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Score vs bucket energy for each top line\n",
    "    energies = []\n",
    "    for line in df_topk[\"line\"]:\n",
    "        feats = line_to_features(line)\n",
    "        energies.append(feats[\"bucket_energy\"])\n",
    "\n",
    "    energies = np.array(energies)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(energies, scores)\n",
    "    plt.xlabel(\"Bucket Energy\")\n",
    "    plt.ylabel(\"Pattern Resonance Score\")\n",
    "    plt.title(\"Resonance Score vs Bucket Energy (Top Lines)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"df_topk is not defined or is empty. Run bulk_generate_and_score first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a933e",
   "metadata": {},
   "source": [
    "## Advanced Pattern Space Visualisations & Final Picks\n",
    "\n",
    "This section adds:\n",
    "- A 3D-style view of pattern space: resonance vs median vs bucket energy\n",
    "- Number frequency analysis across the top-K lines\n",
    "- Bucket heatmap for top-K lines\n",
    "- A simple grouped printout of final picks:\n",
    "  - Stable high-resonance patterns\n",
    "  - Mid-resonance variants\n",
    "  - Wildcard lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b39f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use df_topk from bulk_generate_and_score; require it exists\n",
    "if 'df_topk' not in globals() or df_topk.empty:\n",
    "    print(\"df_topk is not defined or empty. Run bulk_generate_and_score first.\")\n",
    "else:\n",
    "    # Limit to top_K for plots (to avoid clutter)\n",
    "    top_K = min(500, len(df_topk))\n",
    "    df_plot = df_topk.iloc[:top_K].copy()\n",
    "\n",
    "    # --- Compute median and bucket_energy for each top line ---\n",
    "    medians = []\n",
    "    energies = []\n",
    "    scores = df_plot[\"score\"].values\n",
    "\n",
    "    for line in df_plot[\"line\"]:\n",
    "        arr = np.array(line, dtype=int)\n",
    "        feats = line_to_features(arr)\n",
    "        medians.append(feats[\"draw_median\"])\n",
    "        energies.append(feats[\"bucket_energy\"])\n",
    "\n",
    "    medians = np.array(medians)\n",
    "    energies = np.array(energies)\n",
    "\n",
    "    # --- 1) 2D \"3D-style\" scatter: energy vs median, colour = resonance score ---\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sc = plt.scatter(medians, energies, c=scores, alpha=0.8)\n",
    "    plt.colorbar(sc, label=\"Pattern Resonance Score\")\n",
    "    plt.xlabel(\"Line Median\")\n",
    "    plt.ylabel(\"Bucket Energy\")\n",
    "    plt.title(\"Pattern Space: Median vs Bucket Energy (Top-K Unique Lines)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 2) Number frequency across top-K lines ---\n",
    "    number_counts = np.zeros(40, dtype=int)  # 1..40\n",
    "    for line in df_plot[\"line\"]:\n",
    "        arr = np.array(line, dtype=int)\n",
    "        for n in arr:\n",
    "            if 1 <= n <= 40:\n",
    "                number_counts[n-1] += 1\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(np.arange(1, 41), number_counts)\n",
    "    plt.xlabel(\"Number\")\n",
    "    plt.ylabel(f\"Count in Top-{top_K} Lines\")\n",
    "    plt.title(\"Number Frequency in High-Resonance Lines\")\n",
    "    plt.xticks(np.arange(1, 41))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 3) Bucket heatmap for top-K lines ---\n",
    "    # Rebuild bucket counts for each line\n",
    "    max_b = max_bucket\n",
    "    bucket_matrix = np.zeros((top_K, max_b + 1), dtype=int)\n",
    "    for idx, line in enumerate(df_plot[\"line\"]):\n",
    "        arr = np.array(line, dtype=int)\n",
    "        counts = np.zeros(max_b + 1, dtype=int)\n",
    "        for n in arr:\n",
    "            b = num_to_bucket(n, bucket_size=5)\n",
    "            if 0 <= b <= max_b:\n",
    "                counts[b] += 1\n",
    "        bucket_matrix[idx, :] = counts\n",
    "\n",
    "    avg_bucket_counts_top = bucket_matrix.mean(axis=0)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(np.arange(len(avg_bucket_counts_top)), avg_bucket_counts_top)\n",
    "    plt.xlabel(\"Bucket Index\")\n",
    "    plt.ylabel(\"Avg count per line\")\n",
    "    plt.title(\"Average Bucket Counts (Top-K High-Resonance Lines)\")\n",
    "    plt.xticks(np.arange(len(avg_bucket_counts_top)))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 4) Final Picks: group lines into categories ---\n",
    "    print(\"\\n=== Final Picks Summary ===\\n\")\n",
    "\n",
    "    # Stable high-resonance patterns: top 10 by score & frequency\n",
    "    top_stable = df_topk.iloc[:10]\n",
    "    print(\">> Stable High-Resonance Patterns (Top 10):\")\n",
    "    for idx, row in top_stable.iterrows():\n",
    "        print(f\"  Rank {idx+1}: line={row['line'].tolist()}  \"\n",
    "              f\"score={row['score']:.3f}  freq={row['frequency']}\")\n",
    "\n",
    "    # Mid-resonance variants: take a slice from the middle of df_topk\n",
    "    mid_start = len(df_topk) // 3\n",
    "    mid_end = min(mid_start + 10, len(df_topk))\n",
    "    mid_slice = df_topk.iloc[mid_start:mid_end]\n",
    "\n",
    "    print(\"\\n>> Mid-Resonance Variant Lines (sample slice):\")\n",
    "    for idx, row in mid_slice.iterrows():\n",
    "        print(f\"  idx {idx}: line={row['line'].tolist()}  \"\n",
    "              f\"score={row['score']:.3f}  freq={row['frequency']}\")\n",
    "\n",
    "    # Wildcard lines: pick 10 random lines from lower half of df_topk\n",
    "    if len(df_topk) > 20:\n",
    "        lower_half = df_topk.iloc[len(df_topk)//2:]\n",
    "        wildcard_sample = lower_half.sample(n=min(10, len(lower_half)), random_state=42)\n",
    "\n",
    "        print(\"\\n>> Wildcard Lines (random from lower half):\")\n",
    "        for idx, row in wildcard_sample.iterrows():\n",
    "            print(f\"  idx {idx}: line={row['line'].tolist()}  \"\n",
    "                  f\"score={row['score']:.3f}  freq={row['frequency']}\")\n",
    "    else:\n",
    "        print(\"\\nNot enough lines for wildcard sampling; df_topk too small.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rev13: multi-run resonance stability analysis ===\n",
    "\n",
    "def multi_run_resonance_stability(\n",
    "    n_runs=5,\n",
    "    n_samples_per_run=10000,\n",
    "    top_n=50,\n",
    "    use_model_mc=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run bulk_generate_and_score multiple times and analyse how often\n",
    "    specific lines appear in the top-N across runs.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "      - line_str\n",
    "      - line (array of 6 ints)\n",
    "      - max_score\n",
    "      - mean_score\n",
    "      - times_seen (in how many runs this line appeared)\n",
    "    \"\"\"\n",
    "    all_frames = []\n",
    "\n",
    "    for r in range(n_runs):\n",
    "        print(f\"\\n=== Resonance run {r+1}/{n_runs} ===\")\n",
    "        df_run = bulk_generate_and_score(\n",
    "            n_samples=n_samples_per_run,\n",
    "            top_n=top_n,\n",
    "            use_model_mc=use_model_mc,\n",
    "            verbose_every=max(1000, n_samples_per_run // 10),\n",
    "        )\n",
    "        df_run = df_run.copy()\n",
    "        df_run[\"run_id\"] = r\n",
    "        all_frames.append(df_run[[\"line_str\", \"line\", \"score\", \"run_id\"]])\n",
    "\n",
    "    if not all_frames:\n",
    "        print(\"No runs executed.\")\n",
    "        return None\n",
    "\n",
    "    df_all = pd.concat(all_frames, axis=0, ignore_index=True)\n",
    "\n",
    "    stability = (\n",
    "        df_all\n",
    "        .groupby(\"line_str\")\n",
    "        .agg(\n",
    "            line=(\"line\", \"first\"),\n",
    "            max_score=(\"score\", \"max\"),\n",
    "            mean_score=(\"score\", \"mean\"),\n",
    "            times_seen=(\"run_id\", \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values([\"times_seen\", \"mean_score\", \"max_score\"], ascending=[False, False, False])\n",
    "    )\n",
    "\n",
    "    print(\"\\nTop resonance-stable lines across runs:\\n\")\n",
    "    print(stability.head(20))\n",
    "\n",
    "    return stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58391c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Rev14: simple Genetic Algorithm search on pattern resonance ===\n",
    "\n",
    "import random\n",
    "\n",
    "def random_line():\n",
    "    return tuple(sorted(random.sample(range(1, 41), 6)))\n",
    "\n",
    "def mutate_line(line):\n",
    "    line = list(line)\n",
    "    if random.random() < 0.5:\n",
    "        # replace one number\n",
    "        idx = random.randrange(6)\n",
    "        new_val = random.randint(1, 40)\n",
    "        while new_val in line:\n",
    "            new_val = random.randint(1, 40)\n",
    "        line[idx] = new_val\n",
    "    else:\n",
    "        # small +/- mutation on one position\n",
    "        idx = random.randrange(6)\n",
    "        delta = random.choice([-3, -2, -1, 1, 2, 3])\n",
    "        new_val = min(40, max(1, line[idx] + delta))\n",
    "        line[idx] = new_val\n",
    "    return tuple(sorted(line))\n",
    "\n",
    "def crossover_lines(a, b):\n",
    "    # single-point crossover\n",
    "    a = list(a)\n",
    "    b = list(b)\n",
    "    point = random.randint(1, 5)\n",
    "    child = sorted(a[:point] + b[point:])\n",
    "    # ensure uniqueness\n",
    "    child = list(dict.fromkeys(child))  # remove duplicates preserving order\n",
    "    while len(child) < 6:\n",
    "        v = random.randint(1, 40)\n",
    "        if v not in child:\n",
    "            child.append(v)\n",
    "    if len(child) > 6:\n",
    "        child = child[:6]\n",
    "    return tuple(sorted(child))\n",
    "\n",
    "def line_fitness(line):\n",
    "    # Use pattern_resonance_score as the primary fitness\n",
    "    score, _ = pattern_resonance_score(line, historical_profile, bucket_count_cols)\n",
    "    return score\n",
    "\n",
    "def genetic_search(\n",
    "    pop_size=120,\n",
    "    num_generations=40,\n",
    "    mutation_rate=0.12,\n",
    "    crossover_rate=0.85,\n",
    "):\n",
    "    \"\"\"Run a simple GA over the space of Lotto lines to maximise pattern resonance.\"\"\"\n",
    "    # Initial population\n",
    "    population = [random_line() for _ in range(pop_size)]\n",
    "\n",
    "    def evaluate_pop(pop):\n",
    "        fit = []\n",
    "        for ln in pop:\n",
    "            fit.append(line_fitness(ln))\n",
    "        return fit\n",
    "\n",
    "    fitness = evaluate_pop(population)\n",
    "\n",
    "    for gen in range(num_generations):\n",
    "        # Selection (tournament)\n",
    "        new_pop = []\n",
    "        while len(new_pop) < pop_size:\n",
    "            # tournament select parents\n",
    "            i1, i2 = random.randrange(pop_size), random.randrange(pop_size)\n",
    "            p1 = population[i1] if fitness[i1] >= fitness[i2] else population[i2]\n",
    "\n",
    "            i3, i4 = random.randrange(pop_size), random.randrange(pop_size)\n",
    "            p2 = population[i3] if fitness[i3] >= fitness[i4] else population[i4]\n",
    "\n",
    "            # Crossover\n",
    "            if random.random() < crossover_rate:\n",
    "                child = crossover_lines(p1, p2)\n",
    "            else:\n",
    "                child = p1\n",
    "\n",
    "            # Mutation\n",
    "            if random.random() < mutation_rate:\n",
    "                child = mutate_line(child)\n",
    "\n",
    "            new_pop.append(child)\n",
    "\n",
    "        population = new_pop\n",
    "        fitness = evaluate_pop(population)\n",
    "\n",
    "        if (gen + 1) % max(1, num_generations // 5) == 0:\n",
    "            best_idx = max(range(pop_size), key=lambda i: fitness[i])\n",
    "            print(f\"Generation {gen+1}/{num_generations} -> best score={fitness[best_idx]:.3f}, line={population[best_idx]}\")\n",
    "\n",
    "    # Final ranking\n",
    "    results = list(zip(population, fitness))\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 20 GA lines by pattern resonance:\")\n",
    "    for rank, (ln, sc) in enumerate(results[:20], start=1):\n",
    "        print(f\"  Rank {rank}: line={list(ln)}  score={sc:.3f}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Rev15: convergence analysis over historical draws (batched, accelerated) ===\n",
    "# Estimate how many model-generated lines are needed to \"hit\" the actual draw.\n",
    "# Uses generate_model_line + (optionally) GPU-accelerated models.\n",
    "\n",
    "import math\n",
    "\n",
    "# Configuration: you can tweak these depending on how heavy you want the run to be.\n",
    "CONV_MAX_ITER_PER_DRAW = 20000   # maximum candidate generations per draw\n",
    "CONV_USE_MODEL_MC = True        # use augmented model (model_mc) if available\n",
    "CONV_BATCH_SIZE = 128           # batch size for line generation per loop\n",
    "\n",
    "def simulate_iterations_to_hit(target_line,\n",
    "                               feature_cols,\n",
    "                               max_iter=CONV_MAX_ITER_PER_DRAW,\n",
    "                               use_model_mc=CONV_USE_MODEL_MC,\n",
    "                               batch_size=CONV_BATCH_SIZE):\n",
    "    \"\"\"Repeatedly call generate_model_line() in batches until we exactly match\n",
    "    `target_line` or reach `max_iter`.\n",
    "\n",
    "    Returns:\n",
    "      iters (int): effective number of generated lines (max_iter if not hit)\n",
    "      hit (bool): True if an exact match was found before max_iter\n",
    "    \"\"\"\n",
    "    target_line = np.sort(np.array(target_line, dtype=int))\n",
    "    total_generated = 0\n",
    "\n",
    "    while total_generated < max_iter:\n",
    "        cur_batch = min(batch_size, max_iter - total_generated)\n",
    "\n",
    "        lines = []\n",
    "        for _ in range(cur_batch):\n",
    "            cand = generate_model_line(feature_cols, use_model_mc=use_model_mc)\n",
    "            cand = np.sort(np.array(cand, dtype=int))\n",
    "            lines.append(cand)\n",
    "\n",
    "        for i, cand in enumerate(lines, start=1):\n",
    "            if np.array_equal(cand, target_line):\n",
    "                return total_generated + i, True\n",
    "\n",
    "        total_generated += cur_batch\n",
    "\n",
    "    return max_iter, False\n",
    "\n",
    "def build_convergence_table(df_real_feat,\n",
    "                            feature_cols,\n",
    "                            max_iter=CONV_MAX_ITER_PER_DRAW,\n",
    "                            use_model_mc=CONV_USE_MODEL_MC,\n",
    "                            draw_limit=None):\n",
    "    \"\"\"For each historical draw in df_real_feat, estimate how many model-generated\n",
    "    lines are needed to hit that exact combination.\n",
    "\n",
    "    Args:\n",
    "      df_real_feat: DataFrame with real draws (must contain Winning Number 1..6).\n",
    "      feature_cols: feature column list used by the model.\n",
    "      max_iter: maximum candidate generations per draw.\n",
    "      use_model_mc: whether to use the augmented model ensemble.\n",
    "      draw_limit: if not None, only process the first `draw_limit` rows.\n",
    "\n",
    "    Returns:\n",
    "      DataFrame with per-draw convergence stats.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    n_total = len(df_real_feat)\n",
    "    if draw_limit is not None:\n",
    "        n = min(n_total, draw_limit)\n",
    "    else:\n",
    "        n = n_total\n",
    "\n",
    "    print(f\"Running convergence simulation for {n} draws (max_iter={max_iter}, batch_size={CONV_BATCH_SIZE})...\")\n",
    "\n",
    "    for idx in range(n):\n",
    "        row = df_real_feat.iloc[idx]\n",
    "        # Extract actual winning line\n",
    "        actual_line = np.sort(np.array([\n",
    "            row[\"Winning Number 1\"],\n",
    "            row[\"2\"],\n",
    "            row[\"3\"],\n",
    "            row[\"4\"],\n",
    "            row[\"5\"],\n",
    "            row[\"6\"],\n",
    "        ], dtype=int))\n",
    "\n",
    "        iters, hit = simulate_iterations_to_hit(\n",
    "            actual_line,\n",
    "            feature_cols=feature_cols,\n",
    "            max_iter=max_iter,\n",
    "            use_model_mc=use_model_mc,\n",
    "            batch_size=CONV_BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "        log_iters = math.log10(iters) if iters > 0 else 0.0\n",
    "\n",
    "        rows.append({\n",
    "            \"Draw\": row.get(\"Draw\", idx),\n",
    "            \"Date\": row.get(\"Date\", None),\n",
    "            \"actual_line\": actual_line,\n",
    "            \"iters_to_hit\": iters,\n",
    "            \"log10_iters\": log_iters,\n",
    "            \"hit\": hit,\n",
    "        })\n",
    "\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"  Processed {idx+1}/{n} draws...\")\n",
    "\n",
    "    df_conv = pd.DataFrame(rows)\n",
    "    print(\"\\nConvergence table built. Example rows:\")\n",
    "    print(df_conv.head())\n",
    "\n",
    "    return df_conv\n",
    "\n",
    "# Convenience runner (you can adjust draw_limit and max_iter for testing vs full run)\n",
    "# Example:\n",
    "df_convergence = build_convergence_table(\n",
    "    df_real_feat,\n",
    "    feature_cols=feature_cols,\n",
    "    max_iter=CONV_MAX_ITER_PER_DRAW,\n",
    "    use_model_mc=CONV_USE_MODEL_MC,\n",
    "    draw_limit=10,   # or None for full history\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61db4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Rev15: convergence visualisation pack ===\n",
    "# Requires df_convergence from build_convergence_table(...)\n",
    "\n",
    "if \"df_convergence\" in globals() and df_convergence is not None and not df_convergence.empty:\n",
    "    print(\"Head of convergence table:\")\n",
    "    print(df_convergence.head(20))\n",
    "\n",
    "    # Easiest and hardest draws\n",
    "    df_easy = df_convergence.sort_values(\"iters_to_hit\").head(10)\n",
    "    df_hard = df_convergence.sort_values(\"iters_to_hit\", ascending=False).head(10)\n",
    "\n",
    "    print(\"\\nEasiest 10 draws for the model to hit:\")\n",
    "    for _, r in df_easy.iterrows():\n",
    "        print(f\"Draw {r['Draw']} Date={r['Date']} line={list(r['actual_line'])} \"\n",
    "              f\"iters={int(r['iters_to_hit'])} hit={r['hit']}\")\n",
    "\n",
    "    print(\"\\nHardest 10 draws (within the max_iter cap):\")\n",
    "    for _, r in df_hard.iterrows():\n",
    "        print(f\"Draw {r['Draw']} Date={r['Date']} line={list(r['actual_line'])} \"\n",
    "              f\"iters={int(r['iters_to_hit'])} hit={r['hit']}\")\n",
    "\n",
    "    # 1) Time-series / index plot of log10(iters)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    x_axis = np.arange(len(df_convergence))\n",
    "    plt.plot(x_axis, df_convergence[\"log10_iters\"])\n",
    "    plt.xlabel(\"Draw index (0 = oldest)\")\n",
    "    plt.ylabel(\"log10(iterations to hit)\")\n",
    "    plt.title(\"Model Convergence Difficulty per Draw\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Histogram of convergence difficulty\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df_convergence[\"log10_iters\"], bins=30)\n",
    "    plt.xlabel(\"log10(iterations to hit)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of Convergence Difficulty\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Boxplot of difficulty\n",
    "    plt.figure(figsize=(4, 5))\n",
    "    plt.boxplot(df_convergence[\"log10_iters\"], vert=True)\n",
    "    plt.ylabel(\"log10(iterations to hit)\")\n",
    "    plt.title(\"Convergence Difficulty Spread\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4) Optional: scatter of difficulty vs date (if Date is available and datetime-like)\n",
    "    if \"Date\" in df_convergence.columns:\n",
    "        try:\n",
    "            dates = pd.to_datetime(df_convergence[\"Date\"])\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.scatter(dates, df_convergence[\"log10_iters\"], s=8)\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"log10(iterations to hit)\")\n",
    "            plt.title(\"Convergence Difficulty Over Time\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(\"Could not plot difficulty vs Date:\", e)\n",
    "else:\n",
    "    print(\"df_convergence not defined or empty. Run build_convergence_table(...) first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f57ba",
   "metadata": {},
   "source": [
    "## Rev16 – TensorFlow Deep Classifier & Hybrid Resonance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd3b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rev16: TensorFlow deep classifier + hybrid resonance + advanced analysis ===\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    TF_AVAILABLE = True\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    print(\"TF devices:\", tf.config.list_physical_devices())\n",
    "    print(\"TF GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "except ImportError:\n",
    "    TF_AVAILABLE = False\n",
    "    print(\"TensorFlow not installed; Rev16 deep model features will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e14b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build real vs synthetic dataset for TensorFlow classifier\n",
    "# Requires: df_real_feat, df_synth_feat, feature_cols\n",
    "\n",
    "def build_tf_training_data(df_real_feat, df_synth_feat, feature_cols, neg_to_pos_ratio: float = 1.0):\n",
    "    \"\"\"Prepare a binary classification dataset:\n",
    "      class 1 = historical draws, class 0 = synthetic draws.\"\"\"\n",
    "    df_synth_local = df_synth_feat.copy()\n",
    "    for col in feature_cols:\n",
    "        if col not in df_synth_local.columns:\n",
    "            df_synth_local[col] = 0.0\n",
    "\n",
    "    X_pos = df_real_feat[feature_cols].to_numpy(dtype=\"float32\")\n",
    "    X_neg_full = df_synth_local[feature_cols].to_numpy(dtype=\"float32\")\n",
    "\n",
    "    n_pos = len(X_pos)\n",
    "    n_neg_target = int(neg_to_pos_ratio * n_pos)\n",
    "    if len(X_neg_full) > n_neg_target and n_neg_target > 0:\n",
    "        idx = np.random.choice(len(X_neg_full), size=n_neg_target, replace=False)\n",
    "        X_neg = X_neg_full[idx]\n",
    "    else:\n",
    "        X_neg = X_neg_full\n",
    "\n",
    "    y_pos = np.ones((len(X_pos),), dtype=\"float32\")\n",
    "    y_neg = np.zeros((len(X_neg),), dtype=\"float32\")\n",
    "\n",
    "    X_all = np.concatenate([X_pos, X_neg], axis=0)\n",
    "    y_all = np.concatenate([y_pos, y_neg], axis=0)\n",
    "\n",
    "    perm = np.random.permutation(len(X_all))\n",
    "    return X_all[perm], y_all[perm]\n",
    "\n",
    "tf_model = None\n",
    "if TF_AVAILABLE:\n",
    "    print(\"Building TF real vs synthetic training data...\")\n",
    "    X_tf, y_tf = build_tf_training_data(df_real_feat, df_synth_feat, feature_cols, neg_to_pos_ratio=1.0)\n",
    "    print(\"TF dataset shapes:\", X_tf.shape, y_tf.shape)\n",
    "\n",
    "    n_total_tf = len(X_tf)\n",
    "    n_train_tf = int(0.8 * n_total_tf)\n",
    "    X_train_tf, X_val_tf = X_tf[:n_train_tf], X_tf[n_train_tf:]\n",
    "    y_train_tf, y_val_tf = y_tf[:n_train_tf], y_tf[n_train_tf:]\n",
    "else:\n",
    "    print(\"TF not available; skipping TF dataset build.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tf = None\n",
    "if TF_AVAILABLE:\n",
    "    def build_tf_model(input_dim: int):\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                layers.Input(shape=(input_dim,)),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(128, activation=\"relu\"),\n",
    "                layers.Dropout(0.3),\n",
    "                layers.Dense(64, activation=\"relu\"),\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(32, activation=\"relu\"),\n",
    "                layers.Dense(1, activation=\"sigmoid\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\n",
    "                \"accuracy\",\n",
    "                keras.metrics.AUC(name=\"auc\"),\n",
    "            ],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    tf_model = build_tf_model(X_train_tf.shape[1])\n",
    "    print(\"Training TensorFlow classifier (GPU will be used if available)...\")\n",
    "    history_tf = tf_model.fit(\n",
    "        X_train_tf,\n",
    "        y_train_tf,\n",
    "        validation_data=(X_val_tf, y_val_tf),\n",
    "        epochs=25,\n",
    "        batch_size=256,\n",
    "        verbose=2,\n",
    "    )\n",
    "    print(\n",
    "        f\"Final val: loss={history_tf.history['val_loss'][-1]:.4f}, \"\n",
    "        f\"acc={history_tf.history['val_accuracy'][-1]:.4f}, \"\n",
    "        f\"auc={history_tf.history['val_auc'][-1]:.4f}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"TF not available; skipping training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c056522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise TF training curves\n",
    "if history_tf is not None:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(history_tf.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(history_tf.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"TF classifier loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(history_tf.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(history_tf.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"TF classifier accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if \"auc\" in history_tf.history and \"val_auc\" in history_tf.history:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(history_tf.history[\"auc\"], label=\"train_auc\")\n",
    "        plt.plot(history_tf.history[\"val_auc\"], label=\"val_auc\")\n",
    "        plt.title(\"TF classifier AUC\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"AUC\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No TF history to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e776df7",
   "metadata": {},
   "source": [
    "### Rev16 Hybrid Resonance & Advanced Line Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Safe Helper: build_features_from_draw_line for TF scoring ===\n",
    "def build_features_from_draw_line(line_numbers, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Build a 1-row DataFrame of features for a single Lotto line,\n",
    "    using the same logic and column order as the main feature builder.\n",
    "\n",
    "    This wrapper handles both possible signatures of your original\n",
    "    build_features_from_draw(...) implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    if feature_columns is None:\n",
    "        feature_columns = feature_cols  # global list of feature names\n",
    "\n",
    "    # --- Case 1: Try the (line_numbers, feature_columns) signature ---\n",
    "    try:\n",
    "        df = build_features_from_draw(line_numbers, feature_columns)\n",
    "        # Must return a DataFrame\n",
    "        if hasattr(df, \"columns\"):\n",
    "            # ensure correct column order\n",
    "            return df[feature_columns]\n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "    # --- Case 2: Try the (line_numbers) signature ---\n",
    "    try:\n",
    "        df = build_features_from_draw(line_numbers)\n",
    "        if hasattr(df, \"columns\"):\n",
    "            # reorder and ensure correctness\n",
    "            return df[feature_columns]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            f\"build_features_from_draw(...) could not be called with either signature. \"\n",
    "            f\"Original error: {e}\"\n",
    "        )\n",
    "\n",
    "    # If neither worked:\n",
    "    raise RuntimeError(\n",
    "        \"build_features_from_draw_line() could not interpret build_features_from_draw().\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e343d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid resonance: combine pattern_resonance_score with TF \"real-likeness\" probability\n",
    "\n",
    "def hybrid_resonance_score(line_numbers,\n",
    "                           hist_profile=historical_profile,\n",
    "                           bucket_count_cols=bucket_count_cols,\n",
    "                           feature_cols=feature_cols,\n",
    "                           tf_model=tf_model,\n",
    "                           w_pattern: float = 0.5,\n",
    "                           w_tf: float = 0.5):\n",
    "    pattern_score, comps = pattern_resonance_score(line_numbers, hist_profile, bucket_count_cols)\n",
    "\n",
    "    tf_prob = None\n",
    "    if TF_AVAILABLE and (tf_model is not None):\n",
    "        feat_df = build_features_from_draw_line(line_numbers)\n",
    "        X_line = feat_df.to_numpy(dtype=\"float32\")\n",
    "        tf_prob = float(tf_model.predict(X_line, verbose=0)[0][0])\n",
    "        hybrid = float(w_pattern * pattern_score + w_tf * tf_prob)\n",
    "    else:\n",
    "        hybrid = pattern_score\n",
    "\n",
    "    details = {\"pattern\": pattern_score, \"tf_prob\": tf_prob}\n",
    "    details.update(comps)\n",
    "    return hybrid, details\n",
    "\n",
    "print(\"Hybrid resonance check on a few example lines:\")\n",
    "example_lines = [\n",
    "    [3, 8, 14, 27, 33, 38],\n",
    "    [7, 9, 18, 23, 28, 38],\n",
    "    [3, 8, 21, 24, 31, 34],\n",
    "    [1, 2, 3, 4, 5, 6],\n",
    "]\n",
    "for ln in example_lines:\n",
    "    h, d = hybrid_resonance_score(ln)\n",
    "    print(f\"  line={ln} -> hybrid={h:.3f}, pattern={d['pattern']:.3f}, tf_prob={d['tf_prob']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo generation using hybrid resonance scoring\n",
    "\n",
    "def bulk_generate_and_score_hybrid(n_samples=5000,\n",
    "                                   use_model_mc=True,\n",
    "                                   top_n=50,\n",
    "                                   verbose_every=1000):\n",
    "    \"\"\"Generate many lines, score with hybrid_resonance_score, keep top_n unique.\"\"\"\n",
    "    best = {}\n",
    "\n",
    "    for i in range(1, n_samples + 1):\n",
    "        line = generate_model_line(feature_cols, use_model_mc=use_model_mc)\n",
    "        key = tuple(line)\n",
    "        score, comps = hybrid_resonance_score(line)\n",
    "\n",
    "        if key not in best:\n",
    "            best[key] = {\"score\": score, \"freq\": 1, \"components\": comps}\n",
    "        else:\n",
    "            best[key][\"freq\"] += 1\n",
    "            if score > best[key][\"score\"]:\n",
    "                best[key][\"score\"] = score\n",
    "                best[key][\"components\"] = comps\n",
    "\n",
    "        if verbose_every and (i % verbose_every == 0):\n",
    "            print(f\"Generated and scored {i} lines...\")\n",
    "\n",
    "    records = []\n",
    "    for line_t, v in best.items():\n",
    "        row = {\n",
    "            \"line\": list(line_t),\n",
    "            \"score\": v[\"score\"],\n",
    "            \"freq\": v[\"freq\"],\n",
    "        }\n",
    "        row.update(v[\"components\"])\n",
    "        records.append(row)\n",
    "\n",
    "    df_lines = pd.DataFrame(records)\n",
    "    df_lines = df_lines.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Top {top_n} hybrid-resonant lines (out of {n_samples} generated):\\n\")\n",
    "    for i in range(min(top_n, len(df_lines))):\n",
    "        r = df_lines.iloc[i]\n",
    "        print(\n",
    "            f\"Rank {i+1}: line={r['line']}  score={r['score']:.3f}  freq={int(r['freq'])}  \"\n",
    "            f\"(pattern={r['pattern']:.3f}, tf_prob={r['tf_prob']})\"\n",
    "        )\n",
    "\n",
    "    return df_lines\n",
    "\n",
    "# Example smaller run (you can scale n_samples way up):\n",
    "df_top_hybrid = bulk_generate_and_score_hybrid(\n",
    "    n_samples=5000,\n",
    "    use_model_mc=True,\n",
    "    top_n=30,\n",
    "    verbose_every=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse hybrid score distributions for:\n",
    "#  - Real historical draws\n",
    "#  - Pure random lines\n",
    "#  - Model-generated lines\n",
    "\n",
    "def sample_lines_and_scores(num_samples, generator_fn):\n",
    "    scores = []\n",
    "    for _ in range(num_samples):\n",
    "        ln = generator_fn()\n",
    "        s, _ = hybrid_resonance_score(ln)\n",
    "        scores.append(s)\n",
    "    return np.array(scores)\n",
    "\n",
    "num_samples_dist = 2000\n",
    "\n",
    "# Real historical draws\n",
    "real_scores = []\n",
    "for _, row in df_real_feat.iterrows():\n",
    "    line = [int(row[c]) for c in win_cols]\n",
    "    s, _ = hybrid_resonance_score(line)\n",
    "    real_scores.append(s)\n",
    "real_scores = np.array(real_scores)\n",
    "\n",
    "# Pure random\n",
    "random_scores = sample_lines_and_scores(\n",
    "    num_samples_dist,\n",
    "    generator_fn=lambda: sorted(np.random.choice(np.arange(1,41), size=6, replace=False))\n",
    ")\n",
    "\n",
    "# Model-generated\n",
    "model_scores = sample_lines_and_scores(\n",
    "    num_samples_dist,\n",
    "    generator_fn=lambda: generate_model_line(feature_cols, use_model_mc=True)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(real_scores, bins=30, alpha=0.5, label=\"Real draws\")\n",
    "plt.hist(random_scores, bins=30, alpha=0.5, label=\"Pure random\")\n",
    "plt.hist(model_scores, bins=30, alpha=0.5, label=\"Model-generated\")\n",
    "plt.title(\"Hybrid resonance score distributions\")\n",
    "plt.xlabel(\"Hybrid score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean hybrid scores:\")\n",
    "print(\"  Real draws   :\", real_scores.mean())\n",
    "print(\"  Random lines :\", random_scores.mean())\n",
    "print(\"  Model lines  :\", model_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecb419",
   "metadata": {},
   "source": [
    "\n",
    "## Rev17: CHAP Fusion (Chaos / Harmony / Alignment / Probability) and Meta-Fusion\n",
    "\n",
    "In this section we:\n",
    "\n",
    "- Derive **pattern vs TF** agreement metrics (chaos / harmony / alignment)\n",
    "- Build a **meta-dataset** using real vs synthetic draws\n",
    "- Train a light **meta-learner** to fuse pattern and TF scores\n",
    "- Expose a `chap_score_for_line(...)` helper to score individual candidate lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rev17: CHAP metrics and score extraction ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_chap_vectors(pattern_score: np.ndarray, tf_prob: np.ndarray):\n",
    "    \"\"\"Compute CHAP components given arrays of pattern and TF scores.\n",
    "\n",
    "    C: Chaos       -> |tf_prob - pattern_score|\n",
    "    H: Harmony     -> (tf_prob + pattern_score) / 2\n",
    "    A: Alignment   -> 1 - Chaos, clipped to [0, 1]\n",
    "    P_base: simple base hybrid = Harmony * Alignment (not the meta-model yet)\n",
    "    \"\"\"\n",
    "    pattern_score = np.asarray(pattern_score, dtype=\"float32\")\n",
    "    tf_prob = np.asarray(tf_prob, dtype=\"float32\")\n",
    "\n",
    "    chaos = np.abs(tf_prob - pattern_score)\n",
    "    harmony = 0.5 * (tf_prob + pattern_score)\n",
    "    alignment = 1.0 - chaos\n",
    "    alignment = np.clip(alignment, 0.0, 1.0)\n",
    "    base = harmony * alignment\n",
    "    return chaos, harmony, alignment, base\n",
    "\n",
    "\n",
    "def compute_draw_chap_table(df_feat: pd.DataFrame, label: int):\n",
    "    \"\"\"Compute pattern_score, tf_prob and CHAP metrics for each draw in df_feat.\n",
    "\n",
    "    df_feat is expected to contain the original winning numbers in number_cols.\n",
    "    label: 1 for real draws, 0 for synthetic draws.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for idx, row in df_feat.iterrows():\n",
    "        line_numbers = [int(row[c]) for c in number_cols]\n",
    "        # Use existing hybrid_resonance_score to get pattern & tf components\n",
    "        _, details = hybrid_resonance_score(line_numbers)\n",
    "        pattern = details.get(\"pattern\", np.nan)\n",
    "        tf_p = details.get(\"tf_prob\", np.nan)\n",
    "\n",
    "        rows.append({\n",
    "            \"line\": tuple(line_numbers),\n",
    "            \"pattern_score\": pattern,\n",
    "            \"tf_prob\": tf_p,\n",
    "            \"label\": label,\n",
    "        })\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    c, h, a, base = compute_chap_vectors(df_scores[\"pattern_score\"].values,\n",
    "                                         df_scores[\"tf_prob\"].values)\n",
    "    df_scores[\"chap_chaos\"] = c\n",
    "    df_scores[\"chap_harmony\"] = h\n",
    "    df_scores[\"chap_alignment\"] = a\n",
    "    df_scores[\"chap_base\"] = base\n",
    "    return df_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8301f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rev17: build CHAP meta-dataset from real + synthetic draws ===\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "print(\"Building CHAP score tables for real and synthetic draws...\")\n",
    "df_real_chap = compute_draw_chap_table(df_real_feat, label=1)\n",
    "df_synth_chap = compute_draw_chap_table(df_synth_feat, label=0)\n",
    "\n",
    "df_meta = pd.concat([df_real_chap, df_synth_chap], axis=0, ignore_index=True)\n",
    "df_meta = sk_shuffle(df_meta, random_state=42).reset_index(drop=True)\n",
    "print(\"Meta dataset shape:\", df_meta.shape)\n",
    "\n",
    "# Basic diagnostics before any fusion\n",
    "print(\"\\nCorrelation matrix (pattern_score, tf_prob, chap_chaos, chap_harmony, chap_alignment):\")\n",
    "print(\n",
    "    df_meta[[\"pattern_score\", \"tf_prob\", \"chap_chaos\", \"chap_harmony\", \"chap_alignment\"]]\n",
    "    .corr()\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "print(\"\\nSummary stats:\")\n",
    "print(\n",
    "    df_meta[[\"pattern_score\", \"tf_prob\", \"chap_chaos\", \"chap_harmony\", \"chap_alignment\"]]\n",
    "    .describe()\n",
    "    .T\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "# Train a simple logistic regression as the CHAP meta-learner\n",
    "meta_features = [\"pattern_score\", \"tf_prob\", \"chap_chaos\", \"chap_harmony\", \"chap_alignment\"]\n",
    "\n",
    "X_meta = df_meta[meta_features].to_numpy(dtype=\"float32\")\n",
    "y_meta = df_meta[\"label\"].to_numpy(dtype=\"int32\")\n",
    "\n",
    "X_train_m, X_val_m, y_train_m, y_val_m = train_test_split(\n",
    "    X_meta, y_meta, test_size=0.2, random_state=42, stratify=y_meta\n",
    ")\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000, solver=\"lbfgs\")\n",
    "meta_model.fit(X_train_m, y_train_m)\n",
    "\n",
    "y_val_proba = meta_model.predict_proba(X_val_m)[:, 1]\n",
    "y_val_pred = (y_val_proba >= 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"\\nMeta-model AUC:\", roc_auc_score(y_val_m, y_val_proba))\n",
    "print(\"Meta-model accuracy:\", accuracy_score(y_val_m, y_val_pred))\n",
    "print(\"\\nMeta-model coefficients:\")\n",
    "for fname, coef in zip(meta_features, meta_model.coef_[0]):\n",
    "    print(f\"  {fname:>14}: {coef:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rev17: CHAP scoring for a single candidate line ===\n",
    "\n",
    "def chap_score_for_line(line_numbers):\n",
    "    \"\"\"Compute CHAP components and fused probability for a single line.\n",
    "\n",
    "    Uses:\n",
    "      - hybrid_resonance_score (pattern + tf_prob)\n",
    "      - compute_chap_vectors\n",
    "      - meta_model trained in the previous cell\n",
    "\n",
    "    Returns a dict with:\n",
    "      line, pattern_score, tf_prob, chap_chaos, chap_harmony, chap_alignment, chap_base, chap_prob\n",
    "    \"\"\"\n",
    "    # Hybrid details give us pattern and tf contributions\n",
    "    _, details = hybrid_resonance_score(line_numbers)\n",
    "    pattern_score = float(details.get(\"pattern\", np.nan))\n",
    "    tf_prob = float(details.get(\"tf_prob\", np.nan))\n",
    "\n",
    "    c, h, a, base = compute_chap_vectors(\n",
    "        np.array([pattern_score]), np.array([tf_prob])\n",
    "    )\n",
    "    chaos = float(c[0])\n",
    "    harmony = float(h[0])\n",
    "    alignment = float(a[0])\n",
    "    base_hybrid = float(base[0])\n",
    "\n",
    "    meta_input = np.array([[pattern_score, tf_prob, chaos, harmony, alignment]], dtype=\"float32\")\n",
    "    chap_prob = float(meta_model.predict_proba(meta_input)[0, 1])\n",
    "\n",
    "    return {\n",
    "        \"line\": list(line_numbers),\n",
    "        \"pattern_score\": pattern_score,\n",
    "        \"tf_prob\": tf_prob,\n",
    "        \"chap_chaos\": chaos,\n",
    "        \"chap_harmony\": harmony,\n",
    "        \"chap_alignment\": alignment,\n",
    "        \"chap_base\": base_hybrid,\n",
    "        \"chap_prob\": chap_prob,\n",
    "    }\n",
    "\n",
    "# Quick sanity check on a few lines\n",
    "example_lines_rev17 = [\n",
    "    [3, 8, 14, 27, 33, 38],\n",
    "    [7, 9, 18, 23, 28, 38],\n",
    "    [3, 8, 21, 24, 31, 34],\n",
    "    [1, 2, 3, 4, 5, 6],\n",
    "]\n",
    "\n",
    "print(\"\\nRev17 CHAP scoring examples:\")\n",
    "for ln in example_lines_rev17:\n",
    "    res = chap_score_for_line(ln)\n",
    "    print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
