{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563910e0",
   "metadata": {},
   "source": [
    "# Lotto XGBoost with 5-Number Buckets (Named Ranges)\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads `Lotto_DATE.xlsx` (NZ Lotto draw history).\n",
    "2. Builds **5-number bucket features** with meaningful names, e.g. `bucket_1_5_count`, `bucket_6_10_count`, etc.\n",
    "3. Adds simple extra features (Odd/Even, date parts, etc.).\n",
    "4. Trains an **XGBoost multi-output regressor** (one target per winning number).\n",
    "5. Performs 5-fold cross-validation.\n",
    "6. Demonstrates generating candidate draws and predicting with the best model.\n",
    "7. Saves the expanded dataset (with new features) as `Lotto5_Imputed.xlsx`.\n",
    "\n",
    "Place this notebook in the same folder as `Lotto5.xlsx` and run all cells top to bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bdfee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b13d35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1464, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Draw</th>\n",
       "      <th>Date</th>\n",
       "      <th>Winning Number 1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Supplementary Number</th>\n",
       "      <th>From Last</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Odd</th>\n",
       "      <th>Even</th>\n",
       "      <th>1-10</th>\n",
       "      <th>11-20</th>\n",
       "      <th>21-30</th>\n",
       "      <th>31-40</th>\n",
       "      <th>Division 1 Winners</th>\n",
       "      <th>Division 1 Prize</th>\n",
       "      <th>Division 2 Winners</th>\n",
       "      <th>Division 2 Prize</th>\n",
       "      <th>Division 3 Winners</th>\n",
       "      <th>Division 3 Prize</th>\n",
       "      <th>Division 4 Winners</th>\n",
       "      <th>Division 4 Prize</th>\n",
       "      <th>Division 5 Winners</th>\n",
       "      <th>Division 5 Prize</th>\n",
       "      <th>Division 6 Winners</th>\n",
       "      <th>Division 6 Prize</th>\n",
       "      <th>Division 7 Winners</th>\n",
       "      <th>Division 7 Prize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2537</td>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16290.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12979.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18258.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>185398.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2536</td>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>2,10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11489.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20291.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26709.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>254719.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2535</td>\n",
       "      <td>2025-11-19</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16772.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17552.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22725.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>232598.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2534</td>\n",
       "      <td>2025-11-15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55556.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16909.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>68364.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>89904.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>952797.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2533</td>\n",
       "      <td>2025-11-12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>166667.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32541.0</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>46570.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56635.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>626052.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Draw        Date  Winning Number 1   2   3   4   5   6  Supplementary Number From Last  Low  High  Odd  Even  1-10  11-20  21-30  31-40  Division 1 Winners  Division 1 Prize  Division 2 Winners  \\\n",
       "0  2537  2025-11-26                 4   5   9  21  32  34                     3       NaN    3     3    3     3     3      0      1      2                 2.0          500000.0                13.0   \n",
       "1  2536  2025-11-22                 2   6  10  12  28  30                    22      2,10    4     2    0     6     3      1      2      0                 5.0          200000.0                22.0   \n",
       "2  2535  2025-11-19                 2  10  18  25  29  31                    21         2    3     3    3     3     2      1      2      1                 0.0               0.0                15.0   \n",
       "3  2534  2025-11-15                 2   5  14  19  28  38                    29        19    4     2    2     4     2      2      1      1                18.0           55556.0                62.0   \n",
       "4  2533  2025-11-12                 4  10  18  19  27  30                    32         4    4     2    2     4     2      2      2      0                 6.0          166667.0                20.0   \n",
       "\n",
       "   Division 2 Prize  Division 3 Winners  Division 3 Prize  Division 4 Winners  Division 4 Prize  Division 5 Winners  Division 5 Prize  Division 6 Winners  Division 6 Prize  Division 7 Winners  \\\n",
       "0           16290.0               300.0             700.0               802.0              60.0             12979.0              32.0             18258.0              22.0            185398.0   \n",
       "1           11489.0               548.0             457.0              1372.0              42.0             20291.0              25.0             26709.0              18.0            254719.0   \n",
       "2           16772.0               423.0             590.0              1088.0              53.0             17552.0              28.0             22725.0              21.0            232598.0   \n",
       "3           16909.0              1777.0             585.0              4196.0              57.0             68364.0              30.0             89904.0              23.0            952797.0   \n",
       "4           32541.0              1172.0             551.0              2489.0              59.0             46570.0              28.0             56635.0              22.0            626052.0   \n",
       "\n",
       "   Division 7 Prize  \n",
       "0               1.5  \n",
       "1               1.5  \n",
       "2               1.5  \n",
       "3               1.5  \n",
       "4               1.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns: ['Draw', 'Date', 'Winning Number 1', '2', '3', '4', '5', '6', 'Supplementary Number', 'From Last', 'Low', 'High', 'Odd', 'Even', '1-10', '11-20', '21-30', '31-40', 'Division 1 Winners', 'Division 1 Prize', 'Division 2 Winners', 'Division 2 Prize', 'Division 3 Winners', 'Division 3 Prize', 'Division 4 Winners', 'Division 4 Prize', 'Division 5 Winners', 'Division 5 Prize', 'Division 6 Winners', 'Division 6 Prize', 'Division 7 Winners', 'Division 7 Prize']\n"
     ]
    }
   ],
   "source": [
    "# Path to your Excel file. Ensure Lotto_2025-11-26.xlsx is in the same directory as this notebook.\n",
    "excel_path = \"Lotto_2025-11-26.xlsx\"\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "print(\"Data shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nColumns:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb252b",
   "metadata": {},
   "source": [
    "## Basic cleaning and helper columns\n",
    "\n",
    "We:\n",
    "\n",
    "- Ensure the winning number columns are numeric.\n",
    "- Convert helper columns like `From Last`, `Same As Day`, `Odd`, `Even` to numeric (if present).\n",
    "- Parse `Date` and add simple date features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269a61c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected column 'Winning Number 2' not found in dataframe.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m         df[col] = pd.to_numeric(df[col], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected column \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in dataframe.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Helper columns that may exist\u001b[39;00m\n\u001b[32m     19\u001b[39m helper_cols = [\u001b[33m\"\u001b[39m\u001b[33mFrom Last\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSame As Day\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mOdd\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEven\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Expected column 'Winning Number 2' not found in dataframe."
     ]
    }
   ],
   "source": [
    "# Winning number columns (targets)\n",
    "number_cols = [\n",
    "    \"Winning Number 1\",\n",
    "    \"Winning Number 2\",\n",
    "    \"Winning Number 3\",\n",
    "    \"Winning Number 4\",\n",
    "    \"Winning Number 5\",\n",
    "    \"Winning Number 6\",\n",
    "]\n",
    "\n",
    "# Ensure numeric for winning numbers\n",
    "for col in number_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected column '{col}' not found in dataframe.\")\n",
    "\n",
    "# Helper columns that may exist\n",
    "helper_cols = [\"From Last\", \"Same As Day\", \"Odd\", \"Even\"]\n",
    "for col in helper_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Date handling\n",
    "if \"Date\" in df.columns:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df[\"Year\"] = df[\"Date\"].dt.year.fillna(0).astype(int)\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month.fillna(0).astype(int)\n",
    "    df[\"DayOfWeek\"] = df[\"Date\"].dt.dayofweek.fillna(0).astype(int)\n",
    "else:\n",
    "    df[\"Year\"] = 0\n",
    "    df[\"Month\"] = 0\n",
    "    df[\"DayOfWeek\"] = 0\n",
    "\n",
    "print(\"After basic cleaning:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d4379",
   "metadata": {},
   "source": [
    "## 5-number bucket features with named ranges\n",
    "\n",
    "We map numbers as follows (for NZ Lotto 1–40):\n",
    "\n",
    "- 1–5   → bucket index 0 → features: `bucket_1_5_count`, `bucket_1_5_present`\n",
    "- 6–10  → bucket index 1 → `bucket_6_10_count`, ...\n",
    "- 11–15 → bucket index 2\n",
    "- 16–20 → bucket index 3\n",
    "- 21–25 → bucket index 4\n",
    "- 26–30 → bucket index 5\n",
    "- 31–35 → bucket index 6\n",
    "- 36–40 → bucket index 7\n",
    "\n",
    "So you can immediately see which 5-number range each feature refers to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_bucket(num: float, bucket_size: int = 5) -> float:\n",
    "    \"\"\"Map a lotto number to a 0-based bucket index of size `bucket_size`.\n",
    "    Returns NaN for missing values.\n",
    "    \"\"\"\n",
    "    if pd.isna(num):\n",
    "        return np.nan\n",
    "    return int((int(num) - 1) // bucket_size)\n",
    "\n",
    "# Create per-number bucket columns (indices)\n",
    "for col in number_cols:\n",
    "    df[f\"{col}_bucket\"] = df[col].apply(num_to_bucket)\n",
    "\n",
    "bucket_cols = [f\"{col}_bucket\" for col in number_cols]\n",
    "max_bucket = int(df[bucket_cols].max().max())\n",
    "\n",
    "# Infer max actual number from data (e.g. 40)\n",
    "max_number = int(df[number_cols].max().max())\n",
    "bucket_size = 5\n",
    "\n",
    "# Build mapping from bucket index -> human-readable column names\n",
    "bucket_index_to_count_col = {}\n",
    "bucket_index_to_present_col = {}\n",
    "bucket_count_cols = []\n",
    "bucket_present_cols = []\n",
    "\n",
    "for i in range(max_bucket + 1):\n",
    "    low = i * bucket_size + 1\n",
    "    high = min((i + 1) * bucket_size, max_number)\n",
    "    count_name = f\"bucket_{low}_{high}_count\"\n",
    "    present_name = f\"bucket_{low}_{high}_present\"\n",
    "    bucket_index_to_count_col[i] = count_name\n",
    "    bucket_index_to_present_col[i] = present_name\n",
    "    bucket_count_cols.append(count_name)\n",
    "    bucket_present_cols.append(present_name)\n",
    "\n",
    "print(\"Bucket index to feature names:\")\n",
    "for i in range(max_bucket + 1):\n",
    "    print(i, \"->\", bucket_index_to_count_col[i], \",\", bucket_index_to_present_col[i])\n",
    "\n",
    "display(df[bucket_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b526d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bucket counts per draw using the named columns\n",
    "def bucket_count_row(row):\n",
    "    counts = np.zeros(max_bucket + 1, dtype=int)\n",
    "    buckets = row[bucket_cols].values\n",
    "    for b in buckets:\n",
    "        if not pd.isna(b):\n",
    "            b_int = int(b)\n",
    "            if 0 <= b_int <= max_bucket:\n",
    "                counts[b_int] += 1\n",
    "    # Map counts into named columns\n",
    "    data = {}\n",
    "    for i in range(max_bucket + 1):\n",
    "        data[bucket_index_to_count_col[i]] = counts[i]\n",
    "    return pd.Series(data, index=bucket_count_cols)\n",
    "\n",
    "df_bucket_counts = df.apply(bucket_count_row, axis=1)\n",
    "df = pd.concat([df, df_bucket_counts], axis=1)\n",
    "\n",
    "# Presence flags using named columns\n",
    "for i in range(max_bucket + 1):\n",
    "    count_col = bucket_index_to_count_col[i]\n",
    "    present_col = bucket_index_to_present_col[i]\n",
    "    df[present_col] = (df[count_col] > 0).astype(int)\n",
    "\n",
    "# Bucket energy (weighted sum of bucket indices by count)\n",
    "df[\"bucket_energy\"] = 0\n",
    "for i in range(max_bucket + 1):\n",
    "    count_col = bucket_index_to_count_col[i]\n",
    "    df[\"bucket_energy\"] += i * df[count_col]\n",
    "\n",
    "print(\"Bucket features created (named ranges):\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12df635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save expanded dataset with new features\n",
    "output_excel_path = \"Lotto_2025-11-26_Imputed.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "print(f\"Saved dataset with new features to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2a4fe",
   "metadata": {},
   "source": [
    "## Build feature matrix and target matrix\n",
    "\n",
    "- **Targets**: the six winning numbers as a 6D regression target.\n",
    "- **Features**: named bucket counts/presence, bucket energy, helper columns, and date parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = number_cols.copy()\n",
    "\n",
    "# bucket_count_cols and bucket_present_cols already defined with meaningful names\n",
    "candidate_feature_cols = (\n",
    "    bucket_count_cols\n",
    "    + bucket_present_cols\n",
    "    + [\"bucket_energy\", \"From Last\", \"Same As Day\", \"Odd\", \"Even\", \"Year\", \"Month\", \"DayOfWeek\"]\n",
    ")\n",
    "\n",
    "# Keep only columns that exist in df (in case some helper cols are missing)\n",
    "feature_cols = [c for c in candidate_feature_cols if c in df.columns]\n",
    "\n",
    "print(\"Using feature columns:\")\n",
    "print(feature_cols)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target matrix shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5e335",
   "metadata": {},
   "source": [
    "## XGBoost model with cross-validation\n",
    "\n",
    "We use:\n",
    "\n",
    "- `SimpleImputer` to handle any missing feature values.\n",
    "- `MultiOutputRegressor(XGBRegressor)` to predict all 6 numbers at once.\n",
    "- 5-fold cross-validation with **negative MSE** scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base XGBoost regressor\n",
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",  # change to 'gpu_hist' if you have GPU XGBoost installed\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"regressor\", MultiOutputRegressor(xgb_reg)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "test_scores = -cv_results[\"test_score\"]  # convert back to positive MSE\n",
    "print(\"Cross-validation MSE scores:\", test_scores)\n",
    "print(\"Mean CV MSE:\", np.mean(test_scores))\n",
    "\n",
    "best_model_index = np.argmin(test_scores)\n",
    "best_model = cv_results[\"estimator\"][best_model_index]\n",
    "print(\"Best model index:\", best_model_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f618e9",
   "metadata": {},
   "source": [
    "## Predicting from candidate draws\n",
    "\n",
    "To keep things simple, we:\n",
    "\n",
    "1. Generate a **candidate draw** (6 random numbers 1–40, no replacement).\n",
    "2. Build the same **bucket-based features** (with named ranges) for that draw.\n",
    "3. Use the best cross-validated model to predict a 6D output.\n",
    "4. Map predictions back into the 1–40 range (wrapping with modulo).\n",
    "\n",
    "This is more for exploration / \"pattern resonance\" than real prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83505379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_from_draw(draw_numbers, feature_columns, max_bucket_local=None, bucket_size_local=5):\n",
    "    \"\"\"Build a one-row feature DataFrame for a candidate draw using the same\n",
    "    bucket logic and feature columns as the training data.\n",
    "    \"\"\"\n",
    "    draw_numbers = np.array(draw_numbers, dtype=int)\n",
    "    if max_bucket_local is None:\n",
    "        max_bucket_local = max_bucket\n",
    "\n",
    "    # bucket counts\n",
    "    counts = np.zeros(max_bucket_local + 1, dtype=int)\n",
    "    for n in draw_numbers:\n",
    "        b = num_to_bucket(n, bucket_size=bucket_size_local)\n",
    "        if 0 <= b <= max_bucket_local:\n",
    "            counts[b] += 1\n",
    "\n",
    "    row = {}\n",
    "\n",
    "    # bucket counts and presence using named columns\n",
    "    for i in range(max_bucket_local + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        present_col = bucket_index_to_present_col[i]\n",
    "        if count_col in feature_columns:\n",
    "            row[count_col] = counts[i]\n",
    "        if present_col in feature_columns:\n",
    "            row[present_col] = int(counts[i] > 0)\n",
    "\n",
    "    # bucket_energy\n",
    "    if \"bucket_energy\" in feature_columns:\n",
    "        row[\"bucket_energy\"] = sum(i * counts[i] for i in range(max_bucket_local + 1))\n",
    "\n",
    "    # draw-level stats (only if these columns exist in the model)\n",
    "    if \"draw_median\" in feature_columns:\n",
    "        row[\"draw_median\"] = float(np.median(draw_numbers))\n",
    "    if \"draw_mean\" in feature_columns:\n",
    "        row[\"draw_mean\"] = float(np.mean(draw_numbers))\n",
    "    if \"draw_min\" in feature_columns:\n",
    "        row[\"draw_min\"] = int(np.min(draw_numbers))\n",
    "    if \"draw_max\" in feature_columns:\n",
    "        row[\"draw_max\"] = int(np.max(draw_numbers))\n",
    "\n",
    "    # Odd / Even counts (if used as features)\n",
    "    if \"Odd\" in feature_columns:\n",
    "        row[\"Odd\"] = int((draw_numbers % 2 != 0).sum())\n",
    "    if \"Even\" in feature_columns:\n",
    "        row[\"Even\"] = int((draw_numbers % 2 == 0).sum())\n",
    "\n",
    "    # helper + date features (neutral defaults if present in training)\n",
    "    defaults = {\n",
    "        \"From Last\": 0,\n",
    "        \"Same As Day\": 0,\n",
    "        \"Year\": 0,\n",
    "        \"Month\": 0,\n",
    "        \"DayOfWeek\": 0,\n",
    "    }\n",
    "    for col, val in defaults.items():\n",
    "        if col in feature_columns and col not in row:\n",
    "            row[col] = val\n",
    "\n",
    "    # ensure all feature_columns exist\n",
    "    for col in feature_columns:\n",
    "        if col not in row:\n",
    "            row[col] = 0\n",
    "\n",
    "    return pd.DataFrame([row], columns=feature_columns)\n",
    "\n",
    "\n",
    "def sanitize_prediction(raw_pred, n_numbers=6, low=1, high=40):\n",
    "    \"\"\"Convert raw model outputs into a valid NZ Lotto line:\n",
    "    - Round to ints\n",
    "    - Wrap into [low, high] range\n",
    "    - Enforce uniqueness (no duplicates)\n",
    "    - Return sorted array of length n_numbers\n",
    "    \"\"\"\n",
    "    # Map floats to ints in the valid range\n",
    "    ints = ((np.round(raw_pred).astype(int) - 1) % high) + low\n",
    "    ints = np.clip(ints, low, high)\n",
    "\n",
    "    # Enforce uniqueness\n",
    "    uniq = np.unique(ints)\n",
    "\n",
    "    # If we have fewer than required, sample extra distinct numbers\n",
    "    if len(uniq) < n_numbers:\n",
    "        remaining = np.setdiff1d(np.arange(low, high + 1), uniq)\n",
    "        extra = np.random.choice(remaining, size=n_numbers - len(uniq), replace=False)\n",
    "        uniq = np.sort(np.concatenate([uniq, extra]))\n",
    "    # If we have more, truncate to the first n_numbers\n",
    "    elif len(uniq) > n_numbers:\n",
    "        uniq = np.sort(uniq)[:n_numbers]\n",
    "    else:\n",
    "        uniq = np.sort(uniq)\n",
    "\n",
    "    return uniq\n",
    "\n",
    "\n",
    "# Example: generate a few candidate draws and predict\n",
    "num_predictions = 5\n",
    "for i in range(num_predictions):\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "\n",
    "    # Prefer the Monte Carlo-augmented model if available\n",
    "    if \"model_mc\" in globals():\n",
    "        pred = model_mc.predict(input_df.values)[0]\n",
    "        model_used = \"model_mc (augmented)\"\n",
    "    else:\n",
    "        pred = best_model.predict(input_df.values)[0]\n",
    "        model_used = \"best_model (original CV best)\"\n",
    "\n",
    "    predicted_numbers = sanitize_prediction(pred, n_numbers=6, low=1, high=40)\n",
    "\n",
    "    print(f\"Prediction set {i+1} using {model_used}:\")\n",
    "    print(\"  Candidate base numbers:\", candidate_numbers)\n",
    "    print(\"  Model predicted numbers:\", predicted_numbers)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf8fdb-dfa6-469a-8d0d-adf058526a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1bb139",
   "metadata": {},
   "source": [
    "## Monte Carlo Lotto Simulator, Bucket Energy & Delta Export\n",
    "\n",
    "This section:\n",
    "\n",
    "- Reuses the existing 5-number bucket logic.\n",
    "- Computes additional draw-level features like `draw_median`, `draw_mean`, `draw_min`, `draw_max`.\n",
    "- Visualises **bucket energy** and **median** over time.\n",
    "- Builds an **empirical + uniform blended Monte Carlo simulator** to generate many synthetic draws.\n",
    "- Computes the same bucket features for synthetic draws.\n",
    "- Optionally saves both real and synthetic feature tables to **Delta Lake** for ROAPI or other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing dataframe `df` and `number_cols` from earlier cells.\n",
    "# If your raw draws dataframe has a different name, adjust `df_draws` accordingly.\n",
    "df_draws = df  # alias for clarity\n",
    "\n",
    "number_cols = number_cols  # ensure we use the same target columns\n",
    "\n",
    "print(\"Using number columns:\", number_cols)\n",
    "\n",
    "def compute_bucket_features_for_draws(df_base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute bucket count/presence, bucket_energy and draw-level stats for each draw.\"\"\"\n",
    "    df_feat = df_base.copy()\n",
    "\n",
    "    # Map each number to a bucket index using existing num_to_bucket\n",
    "    bucket_indices = df_feat[number_cols].applymap(num_to_bucket)\n",
    "\n",
    "    # Count per bucket into the named bucket_*_count columns\n",
    "    def row_to_bucket_counts(row):\n",
    "        counts = np.zeros(max_bucket + 1, dtype=int)\n",
    "        for b in row.values:\n",
    "            if not pd.isna(b):\n",
    "                b_int = int(b)\n",
    "                if 0 <= b_int <= max_bucket:\n",
    "                    counts[b_int] += 1\n",
    "        data = {}\n",
    "        for i in range(max_bucket + 1):\n",
    "            data[bucket_index_to_count_col[i]] = counts[i]\n",
    "        return pd.Series(data, index=bucket_count_cols)\n",
    "\n",
    "    df_counts = bucket_indices.apply(row_to_bucket_counts, axis=1)\n",
    "    df_feat[df_counts.columns] = df_counts\n",
    "\n",
    "    # Presence flags using named columns\n",
    "    for i in range(max_bucket + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        present_col = bucket_index_to_present_col[i]\n",
    "        df_feat[present_col] = (df_feat[count_col] > 0).astype(int)\n",
    "\n",
    "    # Bucket energy: sum(bucket_index * count)\n",
    "    df_feat[\"bucket_energy\"] = df_counts.apply(\n",
    "        lambda row: sum(i * row[bucket_index_to_count_col[i]] for i in range(max_bucket + 1)),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Draw-level stats from the actual numbers\n",
    "    df_feat[\"draw_median\"] = df_feat[number_cols].median(axis=1)\n",
    "    df_feat[\"draw_mean\"] = df_feat[number_cols].mean(axis=1)\n",
    "    df_feat[\"draw_min\"] = df_feat[number_cols].min(axis=1)\n",
    "    df_feat[\"draw_max\"] = df_feat[number_cols].max(axis=1)\n",
    "\n",
    "    # Odd / Even counts\n",
    "    df_feat[\"Odd\"] = df_feat[number_cols].apply(lambda r: (r % 2 != 0).sum(), axis=1)\n",
    "    df_feat[\"Even\"] = df_feat[number_cols].apply(lambda r: (r % 2 == 0).sum(), axis=1)\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "df_real_feat = compute_bucket_features_for_draws(df_draws)\n",
    "print(\"Real feature table shape:\", df_real_feat.shape)\n",
    "df_real_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations: bucket_energy & draw_median over time, plus distributions\n",
    "x_axis = df_real_feat[\"Date\"] if \"Date\" in df_real_feat.columns else df_real_feat.index\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_axis, df_real_feat[\"bucket_energy\"])\n",
    "plt.title(\"Bucket Energy Over Time (Real Draws)\")\n",
    "plt.xlabel(\"Draw\")\n",
    "plt.ylabel(\"Bucket Energy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_axis, df_real_feat[\"draw_median\"])\n",
    "plt.title(\"Draw Median Over Time (Real Draws)\")\n",
    "plt.xlabel(\"Draw\")\n",
    "plt.ylabel(\"Median of Drawn Numbers\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_real_feat[\"bucket_energy\"], bins=20)\n",
    "plt.title(\"Distribution of Bucket Energy (Real Draws)\")\n",
    "plt.xlabel(\"Bucket Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "avg_counts = df_real_feat[bucket_count_cols].mean()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(range(len(avg_counts)), avg_counts.values)\n",
    "plt.xticks(range(len(avg_counts)), avg_counts.index, rotation=45)\n",
    "plt.title(\"Average Count per 5-Number Bucket (Real Draws)\")\n",
    "plt.ylabel(\"Avg Count per Draw\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical distribution of numbers from real draws\n",
    "def compute_empirical_probs(df_base: pd.DataFrame, number_columns) -> pd.Series:\n",
    "    nums = df_base[number_columns].values.ravel()\n",
    "    values, counts = np.unique(nums, return_counts=True)\n",
    "    n_min = int(nums.min())\n",
    "    n_max = int(nums.max())\n",
    "    all_numbers = np.arange(n_min, n_max + 1)\n",
    "\n",
    "    freq = pd.Series(0, index=all_numbers, dtype=float)\n",
    "    freq.loc[values] = counts\n",
    "    p_emp = freq / freq.sum()\n",
    "    return p_emp\n",
    "\n",
    "p_empirical = compute_empirical_probs(df_draws, number_cols)\n",
    "p_uniform = pd.Series(1.0 / len(p_empirical), index=p_empirical.index, dtype=float)\n",
    "\n",
    "# Blend empirical with uniform so we expand the observed pattern distribution\n",
    "alpha = 0.7  # 70% empirical, 30% uniform\n",
    "p_blended = alpha * p_empirical + (1 - alpha) * p_uniform\n",
    "p_blended = p_blended / p_blended.sum()\n",
    "\n",
    "print(\"First few blended probabilities:\")\n",
    "print(p_blended.head())\n",
    "\n",
    "def simulate_single_draw(draw_size=6, probs: pd.Series = p_blended):\n",
    "    \"\"\"Simulate one lotto draw by sampling without replacement from the blended distribution.\"\"\"\n",
    "    numbers = probs.index.to_numpy()\n",
    "    p = probs.values\n",
    "    sample = np.random.choice(numbers, size=draw_size, replace=False, p=p)\n",
    "    return np.sort(sample)\n",
    "\n",
    "def simulate_dataset(n_draws=100_000, draw_size=6, probs: pd.Series = p_blended):\n",
    "    draws = [simulate_single_draw(draw_size, probs) for _ in range(n_draws)]\n",
    "    df_sim = pd.DataFrame(draws, columns=number_cols[:draw_size])\n",
    "    df_sim[\"SimDrawID\"] = np.arange(1, n_draws + 1)\n",
    "    # Synthetic dates purely for plotting/ordering\n",
    "    df_sim[\"SimDate\"] = pd.date_range(\"2000-01-01\", periods=n_draws, freq=\"D\")\n",
    "    return df_sim\n",
    "\n",
    "N_SYNTH_DRAWS = 50_000  # adjust as you like\n",
    "df_synth = simulate_dataset(N_SYNTH_DRAWS)\n",
    "print(\"Synthetic draws shape:\", df_synth.shape)\n",
    "df_synth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the same bucket features for synthetic draws\n",
    "df_synth_feat = compute_bucket_features_for_draws(df_synth)\n",
    "\n",
    "print(\"Average bucket counts (real):\")\n",
    "print(df_real_feat[bucket_count_cols].mean().round(3))\n",
    "\n",
    "print(\"\\nAverage bucket counts (synthetic):\")\n",
    "print(df_synth_feat[bucket_count_cols].mean().round(3))\n",
    "\n",
    "# Optional: synthetic bucket energy distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_synth_feat[\"bucket_energy\"], bins=20)\n",
    "plt.title(\"Distribution of Bucket Energy (Synthetic Draws)\")\n",
    "plt.xlabel(\"Bucket Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a629b",
   "metadata": {},
   "source": [
    "## Delta Export, Monte Carlo-Augmented Training, and Lotto Number Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd00644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Delta Lake export for real + synthetic feature tables\n",
    "try:\n",
    "    from deltalake import write_deltalake\n",
    "    import pyarrow as pa\n",
    "    HAS_DELTALAKE = True\n",
    "except ImportError:\n",
    "    HAS_DELTALAKE = False\n",
    "    print(\"Warning: 'deltalake' or 'pyarrow' not installed; skipping Delta writes.\")\n",
    "    print(\"Install with: pip install deltalake pyarrow\")\n",
    "    \n",
    "delta_base = Path(\"delta_lotto\")\n",
    "delta_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if HAS_DELTALAKE:\n",
    "    real_delta_path = delta_base / \"real_features\"\n",
    "    synth_delta_path = delta_base / \"synthetic_features\"\n",
    "\n",
    "    # Convert pandas DataFrames to Arrow tables explicitly\n",
    "    real_table = pa.Table.from_pandas(df_real_feat, preserve_index=False)\n",
    "    synth_table = pa.Table.from_pandas(df_synth_feat, preserve_index=False)\n",
    "\n",
    "    print(f\"Writing real feature table to Delta: {real_delta_path}\")\n",
    "    write_deltalake(str(real_delta_path), real_table, mode=\"overwrite\")\n",
    "\n",
    "    print(f\"Writing synthetic feature table to Delta: {synth_delta_path}\")\n",
    "    write_deltalake(str(synth_delta_path), synth_table, mode=\"overwrite\")\n",
    "\n",
    "    print(\"Delta export complete.\")\n",
    "else:\n",
    "    print(\"Delta export skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c107504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain XGBoost on augmented dataset: real + synthetic Monte Carlo draws\n",
    "# We reuse:\n",
    "# - feature_cols: feature column list used originally\n",
    "# - target_cols: the six winning-number columns\n",
    "# - model: the Pipeline(imputer + MultiOutputRegressor(XGBRegressor))\n",
    "\n",
    "# Ensure we have the target columns present in both real and synthetic feature tables\n",
    "missing_targets_real = [c for c in target_cols if c not in df_real_feat.columns]\n",
    "missing_targets_synth = [c for c in target_cols if c not in df_synth_feat.columns]\n",
    "\n",
    "if missing_targets_real or missing_targets_synth:\n",
    "    print(\"Warning: some target columns are missing in real or synthetic tables.\")\n",
    "    print(\"Missing in real:\", missing_targets_real)\n",
    "    print(\"Missing in synthetic:\", missing_targets_synth)\n",
    "else:\n",
    "    # Build augmented dataframe with just the columns we need\n",
    "    cols_needed = feature_cols + target_cols\n",
    "\n",
    "    # Ensure synthetic feature table has all required columns; fill missing with 0\n",
    "    for col in cols_needed:\n",
    "        if col not in df_synth_feat.columns:\n",
    "            df_synth_feat[col] = 0\n",
    "\n",
    "    # Also ensure real feature table has all required columns (defensive)\n",
    "    for col in cols_needed:\n",
    "        if col not in df_real_feat.columns:\n",
    "            df_real_feat[col] = 0\n",
    "\n",
    "    df_real_aug = df_real_feat[cols_needed].copy()\n",
    "    df_synth_aug = df_synth_feat[cols_needed].copy()\n",
    "\n",
    "    df_aug = pd.concat([df_real_aug, df_synth_aug], axis=0, ignore_index=True)\n",
    "    print(\"Augmented dataset shape:\", df_aug.shape)\n",
    "\n",
    "    X_aug = df_aug[feature_cols].values\n",
    "    y_aug = df_aug[target_cols].values\n",
    "\n",
    "    print(\"Augmented feature matrix shape:\", X_aug.shape)\n",
    "    print(\"Augmented target matrix shape:\", y_aug.shape)\n",
    "\n",
    "    # Fit a new model on the full augmented dataset (no extra CV here)\n",
    "    model_mc = model.fit(X_aug, y_aug)\n",
    "    print(\"Monte Carlo-augmented XGBoost model trained and stored as 'model_mc'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example Lotto predictions using the current model (prefers model_mc if available)\n",
    "num_predictions = 5\n",
    "for i in range(num_predictions):\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "\n",
    "    if \"model_mc\" in globals():\n",
    "        pred = model_mc.predict(input_df.values)[0]\n",
    "        model_used = \"model_mc (augmented)\"\n",
    "    else:\n",
    "        pred = best_model.predict(input_df.values)[0]\n",
    "        model_used = \"best_model (original CV best)\"\n",
    "\n",
    "    predicted_numbers = sanitize_prediction(pred, n_numbers=6, low=1, high=40)\n",
    "\n",
    "    print(f\"Prediction set {i+1} using {model_used}:\")\n",
    "    print(\"  Candidate base numbers:\", candidate_numbers)\n",
    "    print(\"  Model predicted numbers:\", predicted_numbers)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e446aae",
   "metadata": {},
   "source": [
    "## Pattern Resonance Scoring & Extra Visualisations\n",
    "\n",
    "This section adds:\n",
    "- A **pattern resonance score** for any predicted Lotto line, comparing it to historical draw structure.\n",
    "- Extra plots comparing **real vs synthetic** distributions and highlighting where model-generated lines sit in feature space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da649b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Pattern resonance helpers ---\n",
    "\n",
    "def line_to_features(line_numbers, max_bucket_local=None, bucket_size_local=5):\n",
    "    \"\"\"Compute a minimal feature dict for a single line of numbers:\n",
    "    - bucket counts\n",
    "    - bucket_energy\n",
    "    - draw_median\n",
    "    - Odd / Even counts\n",
    "    \"\"\"\n",
    "    line_numbers = np.array(line_numbers, dtype=int)\n",
    "    if max_bucket_local is None:\n",
    "        max_bucket_local = max_bucket\n",
    "\n",
    "    # bucket counts\n",
    "    counts = np.zeros(max_bucket_local + 1, dtype=int)\n",
    "    for n in line_numbers:\n",
    "        b = num_to_bucket(n, bucket_size=bucket_size_local)\n",
    "        if 0 <= b <= max_bucket_local:\n",
    "            counts[b] += 1\n",
    "\n",
    "    feats = {}\n",
    "    feats[\"bucket_counts\"] = counts\n",
    "    feats[\"bucket_energy\"] = sum(i * counts[i] for i in range(max_bucket_local + 1))\n",
    "    feats[\"draw_median\"] = float(np.median(line_numbers))\n",
    "    feats[\"Odd\"] = int((line_numbers % 2 != 0).sum())\n",
    "    feats[\"Even\"] = int((line_numbers % 2 == 0).sum())\n",
    "    return feats\n",
    "\n",
    "\n",
    "def compute_historical_profiles(df_real_feat, bucket_count_cols):\n",
    "    \"\"\"Precompute historical reference statistics from real draws.\"\"\"\n",
    "    hist = {}\n",
    "    # Average bucket counts per draw\n",
    "    hist[\"mean_bucket_counts\"] = df_real_feat[bucket_count_cols].mean().values\n",
    "    hist[\"std_bucket_counts\"] = df_real_feat[bucket_count_cols].std(ddof=0).values\n",
    "\n",
    "    # bucket_energy stats\n",
    "    hist[\"mean_bucket_energy\"] = df_real_feat[\"bucket_energy\"].mean()\n",
    "    hist[\"std_bucket_energy\"] = df_real_feat[\"bucket_energy\"].std(ddof=0)\n",
    "\n",
    "    # draw_median stats (if present)\n",
    "    if \"draw_median\" in df_real_feat.columns:\n",
    "        hist[\"mean_draw_median\"] = df_real_feat[\"draw_median\"].mean()\n",
    "        hist[\"std_draw_median\"] = df_real_feat[\"draw_median\"].std(ddof=0)\n",
    "    else:\n",
    "        hist[\"mean_draw_median\"] = None\n",
    "        hist[\"std_draw_median\"] = None\n",
    "\n",
    "    # Odd/Even stats if available\n",
    "    if \"Odd\" in df_real_feat.columns and \"Even\" in df_real_feat.columns:\n",
    "        hist[\"mean_odd\"] = df_real_feat[\"Odd\"].mean()\n",
    "        hist[\"mean_even\"] = df_real_feat[\"Even\"].mean()\n",
    "    else:\n",
    "        hist[\"mean_odd\"] = None\n",
    "        hist[\"mean_even\"] = None\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def pattern_resonance_score(line_numbers, hist_profile, bucket_count_cols):\n",
    "    \"\"\"Compute a 0–1 'pattern resonance' score indicating how Lotto-like\n",
    "    a given line is, compared to historical patterns.\n",
    "\n",
    "    Uses:\n",
    "    - Bucket count distance\n",
    "    - Bucket energy distance (z-score)\n",
    "    - Median distance (z-score)\n",
    "    - Odd/even balance\n",
    "    \"\"\"\n",
    "    feats = line_to_features(line_numbers)\n",
    "    counts = feats[\"bucket_counts\"].astype(float)\n",
    "\n",
    "    # --- Bucket count score (Euclidean distance vs mean, normalized) ---\n",
    "    mean_counts = hist_profile[\"mean_bucket_counts\"]\n",
    "    std_counts = hist_profile[\"std_bucket_counts\"]\n",
    "    # Avoid divide-by-zero\n",
    "    std_counts_safe = np.where(std_counts == 0, 1.0, std_counts)\n",
    "\n",
    "    z_counts = (counts - mean_counts) / std_counts_safe\n",
    "    dist_counts = np.linalg.norm(z_counts)  # higher = further from typical\n",
    "\n",
    "    # Convert distance to score ~ exp(-dist)\n",
    "    bucket_score = np.exp(-dist_counts)\n",
    "\n",
    "    # --- Bucket energy score ---\n",
    "    if hist_profile[\"mean_bucket_energy\"] is not None and hist_profile[\"std_bucket_energy\"] not in (None, 0):\n",
    "        z_energy = (feats[\"bucket_energy\"] - hist_profile[\"mean_bucket_energy\"]) / hist_profile[\"std_bucket_energy\"]\n",
    "        energy_score = np.exp(-abs(z_energy))\n",
    "    else:\n",
    "        energy_score = 1.0\n",
    "\n",
    "    # --- Median score ---\n",
    "    if hist_profile[\"mean_draw_median\"] is not None and hist_profile[\"std_draw_median\"] not in (None, 0):\n",
    "        z_median = (feats[\"draw_median\"] - hist_profile[\"mean_draw_median\"]) / hist_profile[\"std_draw_median\"]\n",
    "        median_score = np.exp(-abs(z_median))\n",
    "    else:\n",
    "        median_score = 1.0\n",
    "\n",
    "    # --- Odd/Even score ---\n",
    "    if hist_profile[\"mean_odd\"] is not None and hist_profile[\"mean_even\"] is not None:\n",
    "        odd_diff = abs(feats[\"Odd\"] - hist_profile[\"mean_odd\"])\n",
    "        even_diff = abs(feats[\"Even\"] - hist_profile[\"mean_even\"])\n",
    "        # Assume typical odd/even deviations of ~1.5 are fine\n",
    "        odd_even_score = np.exp(-(odd_diff + even_diff) / 3.0)\n",
    "    else:\n",
    "        odd_even_score = 1.0\n",
    "\n",
    "    # Combine scores (geometric mean for balance)\n",
    "    scores = np.array([bucket_score, energy_score, median_score, odd_even_score])\n",
    "    pattern_score = float(np.prod(scores) ** (1.0 / len(scores)))\n",
    "    return pattern_score, {\n",
    "        \"bucket_score\": float(bucket_score),\n",
    "        \"energy_score\": float(energy_score),\n",
    "        \"median_score\": float(median_score),\n",
    "        \"odd_even_score\": float(odd_even_score),\n",
    "    }\n",
    "\n",
    "\n",
    "# Precompute historical profile once, if not already done\n",
    "historical_profile = compute_historical_profiles(df_real_feat, bucket_count_cols)\n",
    "print(\"Historical pattern profile computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931edc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Extra visualisations ---\n",
    "\n",
    "# 1) Real vs synthetic average bucket counts\n",
    "if \"df_synth_feat\" in globals():\n",
    "    real_avg_counts = df_real_feat[bucket_count_cols].mean()\n",
    "    synth_avg_counts = df_synth_feat[bucket_count_cols].mean()\n",
    "\n",
    "    x = np.arange(len(bucket_count_cols))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(x - width/2, real_avg_counts.values, width, label=\"Real\")\n",
    "    plt.bar(x + width/2, synth_avg_counts.values, width, label=\"Synthetic MC\")\n",
    "    plt.xticks(x, bucket_count_cols, rotation=45)\n",
    "    plt.ylabel(\"Avg count per draw\")\n",
    "    plt.title(\"Average Bucket Counts: Real vs Monte Carlo Synthetic\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 2) Bucket energy vs median: real vs synthetic\n",
    "plt.figure(figsize=(6, 5))\n",
    "if \"draw_median\" in df_real_feat.columns:\n",
    "    plt.scatter(df_real_feat[\"draw_median\"], df_real_feat[\"bucket_energy\"], alpha=0.3, label=\"Real\")\n",
    "    if \"df_synth_feat\" in globals() and \"draw_median\" in df_synth_feat.columns:\n",
    "        plt.scatter(df_synth_feat[\"draw_median\"], df_synth_feat[\"bucket_energy\"], alpha=0.2, label=\"Synthetic\", marker=\"x\")\n",
    "    plt.xlabel(\"Draw Median\")\n",
    "    plt.ylabel(\"Bucket Energy\")\n",
    "    plt.title(\"Bucket Energy vs Draw Median (Real vs Synthetic)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 3) Example: score and visualise the last N generated prediction lines\n",
    "example_lines = [\n",
    "    np.array([3, 8, 16, 20, 23, 28]),\n",
    "    np.array([3, 12, 18, 26, 29, 33]),\n",
    "    np.array([2, 4, 8, 13, 18, 33]),\n",
    "    np.array([8, 16, 19, 23, 33, 38]),\n",
    "    np.array([3, 6, 9, 19, 37, 39]),\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for line in example_lines:\n",
    "    s, breakdown = pattern_resonance_score(line, historical_profile, bucket_count_cols)\n",
    "    scores.append((line, s, breakdown))\n",
    "\n",
    "print(\"Example pattern resonance scores:\")\n",
    "for line, s, breakdown in scores:\n",
    "    print(f\"Line {line.tolist()} -> score={s:.3f}, components={breakdown}\")\n",
    "\n",
    "# Bar plot of overall scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "labels = [f\"L{i+1}\" for i in range(len(scores))]\n",
    "vals = [s for (_, s, _) in scores]\n",
    "plt.bar(labels, vals)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.ylabel(\"Pattern Resonance Score\")\n",
    "plt.title(\"Pattern Resonance Scores for Example Lines\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af868e7a",
   "metadata": {},
   "source": [
    "## Bulk Generation & Top-N Pattern-Resonant Predictions\n",
    "\n",
    "This section:\n",
    "- Generates a large number of model-based Lotto lines (e.g. 10,000)\n",
    "- Computes the pattern resonance score for each line\n",
    "- Sorts them and shows the top-N most Lotto-like lines according to historical structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_model_line(feature_cols, use_model_mc=True):\n",
    "    \"\"\"Generate a single Lotto line using the current model and sanitiser.\"\"\"\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "\n",
    "    if use_model_mc and \"model_mc\" in globals():\n",
    "        pred = model_mc.predict(input_df.values)[0]\n",
    "    else:\n",
    "        pred = best_model.predict(input_df.values)[0]\n",
    "\n",
    "    line = sanitize_prediction(pred, n_numbers=6, low=1, high=40)\n",
    "    return line\n",
    "\n",
    "\n",
    "def bulk_generate_and_score(\n",
    "    n_samples=10000,\n",
    "    top_n=20,\n",
    "    use_model_mc=True,\n",
    "    verbose_every=1000\n",
    "):\n",
    "    \"\"\"Generate many model-based Lotto lines, score them, and return Top-N\n",
    "    UNIQUE lines sorted by pattern resonance and frequency.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Generate one Lotto line using the ML model\n",
    "        line = generate_model_line(feature_cols, use_model_mc=use_model_mc)\n",
    "\n",
    "        # Score pattern resonance\n",
    "        score, breakdown = pattern_resonance_score(line, historical_profile, bucket_count_cols)\n",
    "\n",
    "        records.append({\n",
    "            \"line\": line,\n",
    "            \"score\": score,\n",
    "            \"bucket_score\": breakdown[\"bucket_score\"],\n",
    "            \"energy_score\": breakdown[\"energy_score\"],\n",
    "            \"median_score\": breakdown[\"median_score\"],\n",
    "            \"odd_even_score\": breakdown[\"odd_even_score\"],\n",
    "        })\n",
    "\n",
    "        if verbose_every and (i + 1) % verbose_every == 0:\n",
    "            print(f\"Generated and scored {i+1} lines...\")\n",
    "\n",
    "    df_scores = pd.DataFrame(records)\n",
    "\n",
    "    # Make a dedupe key: \"3,8,16,20,23,28\"\n",
    "    df_scores[\"line_str\"] = df_scores[\"line\"].apply(lambda arr: \",\".join(map(str, arr)))\n",
    "\n",
    "    # Aggregate unique line stats\n",
    "    grouped = (\n",
    "        df_scores\n",
    "        .groupby(\"line_str\")\n",
    "        .agg(\n",
    "            line=(\"line\", \"first\"),\n",
    "            score=(\"score\", \"max\"),\n",
    "            bucket_score=(\"bucket_score\", \"max\"),\n",
    "            energy_score=(\"energy_score\", \"max\"),\n",
    "            median_score=(\"median_score\", \"max\"),\n",
    "            odd_even_score=(\"odd_even_score\", \"max\"),\n",
    "            frequency=(\"line_str\", \"count\"),\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Sort by score desc, then frequency desc\n",
    "    df_sorted = grouped.sort_values(\n",
    "        by=[\"score\", \"frequency\"],\n",
    "        ascending=[False, False]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\nTop {top_n} UNIQUE pattern-resonant lines out of {n_samples} samples:\\n\")\n",
    "\n",
    "    for idx in range(min(top_n, len(df_sorted))):\n",
    "        row = df_sorted.iloc[idx]\n",
    "        print(\n",
    "            f\"Rank {idx+1}: line={row['line'].tolist()}  \"\n",
    "            f\"score={row['score']:.3f}  freq={row['frequency']}  \"\n",
    "            f\"(bucket={row['bucket_score']:.3f}, \"\n",
    "            f\"energy={row['energy_score']:.3f}, \"\n",
    "            f\"median={row['median_score']:.3f}, \"\n",
    "            f\"odd_even={row['odd_even_score']:.3f})\"\n",
    "        )\n",
    "\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4e8a8-2836-4ef6-99f4-4857eaa9b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topk = bulk_generate_and_score(\n",
    "    n_samples=5000,\n",
    "    top_n=20,\n",
    "    use_model_mc=True,\n",
    "    verbose_every=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7e35f",
   "metadata": {},
   "source": [
    "## Extra Analysis of Top Pattern-Resonant Lines\n",
    "\n",
    "These plots help understand how the top-ranked lines relate to historical structure:\n",
    "- Histogram of resonance scores for the unique top lines\n",
    "- Resonance vs line median\n",
    "- Resonance vs bucket energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure df_topk exists\n",
    "if 'df_topk' in globals() and not df_topk.empty:\n",
    "    # 1) Histogram of resonance scores\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(df_topk[\"score\"], bins=15)\n",
    "    plt.xlabel(\"Pattern Resonance Score\")\n",
    "    plt.ylabel(\"Frequency (unique lines)\")\n",
    "    plt.title(\"Distribution of Pattern Resonance Scores (Top Unique Lines)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Score vs median for each top line\n",
    "    medians = []\n",
    "    scores = df_topk[\"score\"].values\n",
    "\n",
    "    for line in df_topk[\"line\"]:\n",
    "        line_arr = np.array(line, dtype=int)\n",
    "        medians.append(np.median(line_arr))\n",
    "\n",
    "    medians = np.array(medians)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(medians, scores)\n",
    "    plt.xlabel(\"Line Median\")\n",
    "    plt.ylabel(\"Pattern Resonance Score\")\n",
    "    plt.title(\"Resonance Score vs Median of Top Lines\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Score vs bucket energy for each top line\n",
    "    energies = []\n",
    "    for line in df_topk[\"line\"]:\n",
    "        feats = line_to_features(line)\n",
    "        energies.append(feats[\"bucket_energy\"])\n",
    "\n",
    "    energies = np.array(energies)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(energies, scores)\n",
    "    plt.xlabel(\"Bucket Energy\")\n",
    "    plt.ylabel(\"Pattern Resonance Score\")\n",
    "    plt.title(\"Resonance Score vs Bucket Energy (Top Lines)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"df_topk is not defined or is empty. Run bulk_generate_and_score first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
