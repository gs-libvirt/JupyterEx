{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563910e0",
   "metadata": {},
   "source": [
    "# Lotto XGBoost with 5-Number Buckets (Named Ranges)\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Loads `Lotto5.xlsx` (NZ Lotto draw history).\n",
    "2. Builds **5-number bucket features** with meaningful names, e.g. `bucket_1_5_count`, `bucket_6_10_count`, etc.\n",
    "3. Adds simple extra features (Odd/Even, date parts, etc.).\n",
    "4. Trains an **XGBoost multi-output regressor** (one target per winning number).\n",
    "5. Performs 5-fold cross-validation.\n",
    "6. Demonstrates generating candidate draws and predicting with the best model.\n",
    "7. Saves the expanded dataset (with new features) as `Lotto5_Imputed.xlsx`.\n",
    "\n",
    "Place this notebook in the same folder as `Lotto5.xlsx` and run all cells top to bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from deltalake import write_deltalake\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13d35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Excel file. Ensure Lotto5.xlsx is in the same directory as this notebook.\n",
    "excel_path = \"Lotto5.xlsx\"\n",
    "\n",
    "df = pd.read_excel(excel_path)\n",
    "print(\"Data shape:\", df.shape)\n",
    "display(df.head())\n",
    "print(\"\\nColumns:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb252b",
   "metadata": {},
   "source": [
    "## Basic cleaning and helper columns\n",
    "\n",
    "We:\n",
    "\n",
    "- Ensure the winning number columns are numeric.\n",
    "- Convert helper columns like `From Last`, `Same As Day`, `Odd`, `Even` to numeric (if present).\n",
    "- Parse `Date` and add simple date features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winning number columns (targets)\n",
    "number_cols = [\n",
    "    \"Winning Number 1\",\n",
    "    \"Winning Number 2\",\n",
    "    \"Winning Number 3\",\n",
    "    \"Winning Number 4\",\n",
    "    \"Winning Number 5\",\n",
    "    \"Winning Number 6\",\n",
    "]\n",
    "\n",
    "# Ensure numeric for winning numbers\n",
    "for col in number_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected column '{col}' not found in dataframe.\")\n",
    "\n",
    "# Helper columns that may exist\n",
    "helper_cols = [\"From Last\", \"Same As Day\", \"Odd\", \"Even\"]\n",
    "for col in helper_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Date handling\n",
    "if \"Date\" in df.columns:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    df[\"Year\"] = df[\"Date\"].dt.year.fillna(0).astype(int)\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month.fillna(0).astype(int)\n",
    "    df[\"DayOfWeek\"] = df[\"Date\"].dt.dayofweek.fillna(0).astype(int)\n",
    "else:\n",
    "    df[\"Year\"] = 0\n",
    "    df[\"Month\"] = 0\n",
    "    df[\"DayOfWeek\"] = 0\n",
    "\n",
    "print(\"After basic cleaning:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d4379",
   "metadata": {},
   "source": [
    "## 5-number bucket features with named ranges\n",
    "\n",
    "We map numbers as follows (for NZ Lotto 1–40):\n",
    "\n",
    "- 1–5   → bucket index 0 → features: `bucket_1_5_count`, `bucket_1_5_present`\n",
    "- 6–10  → bucket index 1 → `bucket_6_10_count`, ...\n",
    "- 11–15 → bucket index 2\n",
    "- 16–20 → bucket index 3\n",
    "- 21–25 → bucket index 4\n",
    "- 26–30 → bucket index 5\n",
    "- 31–35 → bucket index 6\n",
    "- 36–40 → bucket index 7\n",
    "\n",
    "So you can immediately see which 5-number range each feature refers to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_bucket(num: float, bucket_size: int = 5) -> float:\n",
    "    \"\"\"Map a lotto number to a 0-based bucket index of size `bucket_size`.\n",
    "    Returns NaN for missing values.\n",
    "    \"\"\"\n",
    "    if pd.isna(num):\n",
    "        return np.nan\n",
    "    return int((int(num) - 1) // bucket_size)\n",
    "\n",
    "# Create per-number bucket columns (indices)\n",
    "for col in number_cols:\n",
    "    df[f\"{col}_bucket\"] = df[col].apply(num_to_bucket)\n",
    "\n",
    "bucket_cols = [f\"{col}_bucket\" for col in number_cols]\n",
    "max_bucket = int(df[bucket_cols].max().max())\n",
    "\n",
    "# Infer max actual number from data (e.g. 40)\n",
    "max_number = int(df[number_cols].max().max())\n",
    "bucket_size = 5\n",
    "\n",
    "# Build mapping from bucket index -> human-readable column names\n",
    "bucket_index_to_count_col = {}\n",
    "bucket_index_to_present_col = {}\n",
    "bucket_count_cols = []\n",
    "bucket_present_cols = []\n",
    "\n",
    "for i in range(max_bucket + 1):\n",
    "    low = i * bucket_size + 1\n",
    "    high = min((i + 1) * bucket_size, max_number)\n",
    "    count_name = f\"bucket_{low}_{high}_count\"\n",
    "    present_name = f\"bucket_{low}_{high}_present\"\n",
    "    bucket_index_to_count_col[i] = count_name\n",
    "    bucket_index_to_present_col[i] = present_name\n",
    "    bucket_count_cols.append(count_name)\n",
    "    bucket_present_cols.append(present_name)\n",
    "\n",
    "print(\"Bucket index to feature names:\")\n",
    "for i in range(max_bucket + 1):\n",
    "    print(i, \"->\", bucket_index_to_count_col[i], \",\", bucket_index_to_present_col[i])\n",
    "\n",
    "display(df[bucket_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b526d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bucket counts per draw using the named columns\n",
    "def bucket_count_row(row):\n",
    "    counts = np.zeros(max_bucket + 1, dtype=int)\n",
    "    buckets = row[bucket_cols].values\n",
    "    for b in buckets:\n",
    "        if not pd.isna(b):\n",
    "            b_int = int(b)\n",
    "            if 0 <= b_int <= max_bucket:\n",
    "                counts[b_int] += 1\n",
    "    # Map counts into named columns\n",
    "    data = {}\n",
    "    for i in range(max_bucket + 1):\n",
    "        data[bucket_index_to_count_col[i]] = counts[i]\n",
    "    return pd.Series(data, index=bucket_count_cols)\n",
    "\n",
    "df_bucket_counts = df.apply(bucket_count_row, axis=1)\n",
    "df = pd.concat([df, df_bucket_counts], axis=1)\n",
    "\n",
    "# Presence flags using named columns\n",
    "for i in range(max_bucket + 1):\n",
    "    count_col = bucket_index_to_count_col[i]\n",
    "    present_col = bucket_index_to_present_col[i]\n",
    "    df[present_col] = (df[count_col] > 0).astype(int)\n",
    "\n",
    "# Bucket energy (weighted sum of bucket indices by count)\n",
    "df[\"bucket_energy\"] = 0\n",
    "for i in range(max_bucket + 1):\n",
    "    count_col = bucket_index_to_count_col[i]\n",
    "    df[\"bucket_energy\"] += i * df[count_col]\n",
    "\n",
    "print(\"Bucket features created (named ranges):\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12df635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save expanded dataset with new features\n",
    "output_excel_path = \"Lotto5_Imputed.xlsx\"\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "print(f\"Saved dataset with new features to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2a4fe",
   "metadata": {},
   "source": [
    "## Build feature matrix and target matrix\n",
    "\n",
    "- **Targets**: the six winning numbers as a 6D regression target.\n",
    "- **Features**: named bucket counts/presence, bucket energy, helper columns, and date parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = number_cols.copy()\n",
    "\n",
    "# bucket_count_cols and bucket_present_cols already defined with meaningful names\n",
    "candidate_feature_cols = (\n",
    "    bucket_count_cols\n",
    "    + bucket_present_cols\n",
    "    + [\"bucket_energy\", \"From Last\", \"Same As Day\", \"Odd\", \"Even\", \"Year\", \"Month\", \"DayOfWeek\"]\n",
    ")\n",
    "\n",
    "# Keep only columns that exist in df (in case some helper cols are missing)\n",
    "feature_cols = [c for c in candidate_feature_cols if c in df.columns]\n",
    "\n",
    "print(\"Using feature columns:\")\n",
    "print(feature_cols)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target matrix shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5e335",
   "metadata": {},
   "source": [
    "## XGBoost model with cross-validation\n",
    "\n",
    "We use:\n",
    "\n",
    "- `SimpleImputer` to handle any missing feature values.\n",
    "- `MultiOutputRegressor(XGBRegressor)` to predict all 6 numbers at once.\n",
    "- 5-fold cross-validation with **negative MSE** scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base XGBoost regressor\n",
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",  # change to 'gpu_hist' if you have GPU XGBoost installed\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"regressor\", MultiOutputRegressor(xgb_reg)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    model,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "test_scores = -cv_results[\"test_score\"]  # convert back to positive MSE\n",
    "print(\"Cross-validation MSE scores:\", test_scores)\n",
    "print(\"Mean CV MSE:\", np.mean(test_scores))\n",
    "\n",
    "best_model_index = np.argmin(test_scores)\n",
    "best_model = cv_results[\"estimator\"][best_model_index]\n",
    "print(\"Best model index:\", best_model_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f618e9",
   "metadata": {},
   "source": [
    "## Predicting from candidate draws\n",
    "\n",
    "To keep things simple, we:\n",
    "\n",
    "1. Generate a **candidate draw** (6 random numbers 1–40, no replacement).\n",
    "2. Build the same **bucket-based features** (with named ranges) for that draw.\n",
    "3. Use the best cross-validated model to predict a 6D output.\n",
    "4. Map predictions back into the 1–40 range (wrapping with modulo).\n",
    "\n",
    "This is more for exploration / \"pattern resonance\" than real prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83505379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features_from_draw(draw_numbers, feature_columns, max_bucket_local=None, bucket_size_local=5):\n",
    "    \"\"\"Build a one-row feature DataFrame for a candidate draw using the same\n",
    "    bucket logic and feature columns as the training data.\n",
    "    \"\"\"\n",
    "    draw_numbers = np.array(draw_numbers, dtype=int)\n",
    "    if max_bucket_local is None:\n",
    "        max_bucket_local = max_bucket\n",
    "\n",
    "    # bucket counts\n",
    "    counts = np.zeros(max_bucket_local + 1, dtype=int)\n",
    "    for n in draw_numbers:\n",
    "        b = num_to_bucket(n, bucket_size=bucket_size_local)\n",
    "        if 0 <= b <= max_bucket_local:\n",
    "            counts[b] += 1\n",
    "\n",
    "    row = {}\n",
    "\n",
    "    # bucket counts and presence using named columns\n",
    "    for i in range(max_bucket_local + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        present_col = bucket_index_to_present_col[i]\n",
    "        if count_col in feature_columns:\n",
    "            row[count_col] = counts[i]\n",
    "        if present_col in feature_columns:\n",
    "            row[present_col] = int(counts[i] > 0)\n",
    "\n",
    "    # bucket_energy\n",
    "    if \"bucket_energy\" in feature_columns:\n",
    "        row[\"bucket_energy\"] = sum(i * counts[i] for i in range(max_bucket_local + 1))\n",
    "\n",
    "    # helper + date features (set to neutral values)\n",
    "    defaults = {\n",
    "        \"From Last\": 0,\n",
    "        \"Same As Day\": 0,\n",
    "        \"Odd\": 0,\n",
    "        \"Even\": 0,\n",
    "        \"Year\": 0,\n",
    "        \"Month\": 0,\n",
    "        \"DayOfWeek\": 0,\n",
    "    }\n",
    "    for col, val in defaults.items():\n",
    "        if col in feature_columns and col not in row:\n",
    "            row[col] = val\n",
    "\n",
    "    # ensure all feature_columns exist\n",
    "    for col in feature_columns:\n",
    "        if col not in row:\n",
    "            row[col] = 0\n",
    "\n",
    "    return pd.DataFrame([row], columns=feature_columns)\n",
    "\n",
    "# Example: generate a few candidate draws and predict\n",
    "num_predictions = 5\n",
    "for i in range(num_predictions):\n",
    "    candidate_numbers = np.sort(np.random.choice(np.arange(1, 41), size=6, replace=False))\n",
    "    input_df = build_features_from_draw(candidate_numbers, feature_cols)\n",
    "    pred = best_model.predict(input_df.values)[0]  # shape (6,)\n",
    "\n",
    "    # Map predictions into 1–40 range and round\n",
    "    predicted_numbers = ((np.round(pred).astype(int) - 1) % 40) + 1\n",
    "    predicted_numbers = np.sort(predicted_numbers)\n",
    "\n",
    "    print(f\"Prediction set {i+1}:\")\n",
    "    print(\"  Candidate base numbers:\", candidate_numbers)\n",
    "    print(\"  Model predicted numbers:\", predicted_numbers)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf8fdb-dfa6-469a-8d0d-adf058526a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1bb139",
   "metadata": {},
   "source": [
    "## Monte Carlo Lotto Simulator, Bucket Energy & Delta Export\n",
    "\n",
    "This section:\n",
    "\n",
    "- Reuses the existing 5-number bucket logic.\n",
    "- Computes additional draw-level features like `draw_median`, `draw_mean`, `draw_min`, `draw_max`.\n",
    "- Visualises **bucket energy** and **median** over time.\n",
    "- Builds an **empirical + uniform blended Monte Carlo simulator** to generate many synthetic draws.\n",
    "- Computes the same bucket features for synthetic draws.\n",
    "- Optionally saves both real and synthetic feature tables to **Delta Lake** for ROAPI or other tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing dataframe `df` and `number_cols` from earlier cells.\n",
    "# If your raw draws dataframe has a different name, adjust `df_draws` accordingly.\n",
    "df_draws = df  # alias for clarity\n",
    "\n",
    "number_cols = number_cols  # ensure we use the same target columns\n",
    "\n",
    "print(\"Using number columns:\", number_cols)\n",
    "\n",
    "def compute_bucket_features_for_draws(df_base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute bucket count/presence, bucket_energy and draw-level stats for each draw.\"\"\"\n",
    "    df_feat = df_base.copy()\n",
    "\n",
    "    # Map each number to a bucket index using existing num_to_bucket\n",
    "    bucket_indices = df_feat[number_cols].applymap(num_to_bucket)\n",
    "\n",
    "    # Count per bucket into the named bucket_*_count columns\n",
    "    def row_to_bucket_counts(row):\n",
    "        counts = np.zeros(max_bucket + 1, dtype=int)\n",
    "        for b in row.values:\n",
    "            if not pd.isna(b):\n",
    "                b_int = int(b)\n",
    "                if 0 <= b_int <= max_bucket:\n",
    "                    counts[b_int] += 1\n",
    "        data = {}\n",
    "        for i in range(max_bucket + 1):\n",
    "            data[bucket_index_to_count_col[i]] = counts[i]\n",
    "        return pd.Series(data, index=bucket_count_cols)\n",
    "\n",
    "    df_counts = bucket_indices.apply(row_to_bucket_counts, axis=1)\n",
    "    df_feat[df_counts.columns] = df_counts\n",
    "\n",
    "    # Presence flags using named columns\n",
    "    for i in range(max_bucket + 1):\n",
    "        count_col = bucket_index_to_count_col[i]\n",
    "        present_col = bucket_index_to_present_col[i]\n",
    "        df_feat[present_col] = (df_feat[count_col] > 0).astype(int)\n",
    "\n",
    "    # Bucket energy: sum(bucket_index * count)\n",
    "    df_feat[\"bucket_energy\"] = df_counts.apply(\n",
    "        lambda row: sum(i * row[bucket_index_to_count_col[i]] for i in range(max_bucket + 1)),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Draw-level stats from the actual numbers\n",
    "    df_feat[\"draw_median\"] = df_feat[number_cols].median(axis=1)\n",
    "    df_feat[\"draw_mean\"] = df_feat[number_cols].mean(axis=1)\n",
    "    df_feat[\"draw_min\"] = df_feat[number_cols].min(axis=1)\n",
    "    df_feat[\"draw_max\"] = df_feat[number_cols].max(axis=1)\n",
    "\n",
    "    # Odd / Even counts\n",
    "    df_feat[\"Odd\"] = df_feat[number_cols].apply(lambda r: (r % 2 != 0).sum(), axis=1)\n",
    "    df_feat[\"Even\"] = df_feat[number_cols].apply(lambda r: (r % 2 == 0).sum(), axis=1)\n",
    "\n",
    "    return df_feat\n",
    "\n",
    "df_real_feat = compute_bucket_features_for_draws(df_draws)\n",
    "print(\"Real feature table shape:\", df_real_feat.shape)\n",
    "df_real_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations: bucket_energy & draw_median over time, plus distributions\n",
    "x_axis = df_real_feat[\"Date\"] if \"Date\" in df_real_feat.columns else df_real_feat.index\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_axis, df_real_feat[\"bucket_energy\"])\n",
    "plt.title(\"Bucket Energy Over Time (Real Draws)\")\n",
    "plt.xlabel(\"Draw\")\n",
    "plt.ylabel(\"Bucket Energy\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x_axis, df_real_feat[\"draw_median\"])\n",
    "plt.title(\"Draw Median Over Time (Real Draws)\")\n",
    "plt.xlabel(\"Draw\")\n",
    "plt.ylabel(\"Median of Drawn Numbers\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_real_feat[\"bucket_energy\"], bins=20)\n",
    "plt.title(\"Distribution of Bucket Energy (Real Draws)\")\n",
    "plt.xlabel(\"Bucket Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "avg_counts = df_real_feat[bucket_count_cols].mean()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(range(len(avg_counts)), avg_counts.values)\n",
    "plt.xticks(range(len(avg_counts)), avg_counts.index, rotation=45)\n",
    "plt.title(\"Average Count per 5-Number Bucket (Real Draws)\")\n",
    "plt.ylabel(\"Avg Count per Draw\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical distribution of numbers from real draws\n",
    "def compute_empirical_probs(df_base: pd.DataFrame, number_columns) -> pd.Series:\n",
    "    nums = df_base[number_columns].values.ravel()\n",
    "    values, counts = np.unique(nums, return_counts=True)\n",
    "    n_min = int(nums.min())\n",
    "    n_max = int(nums.max())\n",
    "    all_numbers = np.arange(n_min, n_max + 1)\n",
    "\n",
    "    freq = pd.Series(0, index=all_numbers, dtype=float)\n",
    "    freq.loc[values] = counts\n",
    "    p_emp = freq / freq.sum()\n",
    "    return p_emp\n",
    "\n",
    "p_empirical = compute_empirical_probs(df_draws, number_cols)\n",
    "p_uniform = pd.Series(1.0 / len(p_empirical), index=p_empirical.index, dtype=float)\n",
    "\n",
    "# Blend empirical with uniform so we expand the observed pattern distribution\n",
    "alpha = 0.7  # 70% empirical, 30% uniform\n",
    "p_blended = alpha * p_empirical + (1 - alpha) * p_uniform\n",
    "p_blended = p_blended / p_blended.sum()\n",
    "\n",
    "print(\"First few blended probabilities:\")\n",
    "print(p_blended.head())\n",
    "\n",
    "def simulate_single_draw(draw_size=6, probs: pd.Series = p_blended):\n",
    "    \"\"\"Simulate one lotto draw by sampling without replacement from the blended distribution.\"\"\"\n",
    "    numbers = probs.index.to_numpy()\n",
    "    p = probs.values\n",
    "    sample = np.random.choice(numbers, size=draw_size, replace=False, p=p)\n",
    "    return np.sort(sample)\n",
    "\n",
    "def simulate_dataset(n_draws=100_000, draw_size=6, probs: pd.Series = p_blended):\n",
    "    draws = [simulate_single_draw(draw_size, probs) for _ in range(n_draws)]\n",
    "    df_sim = pd.DataFrame(draws, columns=number_cols[:draw_size])\n",
    "    df_sim[\"SimDrawID\"] = np.arange(1, n_draws + 1)\n",
    "    # Synthetic dates purely for plotting/ordering\n",
    "    df_sim[\"SimDate\"] = pd.date_range(\"2000-01-01\", periods=n_draws, freq=\"D\")\n",
    "    return df_sim\n",
    "\n",
    "N_SYNTH_DRAWS = 50_000  # adjust as you like\n",
    "df_synth = simulate_dataset(N_SYNTH_DRAWS)\n",
    "print(\"Synthetic draws shape:\", df_synth.shape)\n",
    "df_synth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the same bucket features for synthetic draws\n",
    "df_synth_feat = compute_bucket_features_for_draws(df_synth)\n",
    "\n",
    "print(\"Average bucket counts (real):\")\n",
    "print(df_real_feat[bucket_count_cols].mean().round(3))\n",
    "\n",
    "print(\"\\nAverage bucket counts (synthetic):\")\n",
    "print(df_synth_feat[bucket_count_cols].mean().round(3))\n",
    "\n",
    "# Optional: synthetic bucket energy distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_synth_feat[\"bucket_energy\"], bins=20)\n",
    "plt.title(\"Distribution of Bucket Energy (Synthetic Draws)\")\n",
    "plt.xlabel(\"Bucket Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
